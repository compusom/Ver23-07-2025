# report_generator_project/data_processing/report_sections.py
import pandas as pd
import numpy as np
import re # Para bÃºsqueda de U{dias}
import locale # Para nombres de meses
from datetime import datetime, date, timedelta

# Intentar importar dateutil, pero es opcional para algunas funciones si no estÃ¡
try:
    from dateutil.relativedelta import relativedelta
    from dateutil.parser import parse as date_parse
except ImportError:
    relativedelta = None
    date_parse = None

from formatting_utils import (
    fmt_int, fmt_float, fmt_pct, fmt_stability, variation, format_step_pct,
    safe_division, safe_division_pct, _format_dataframe_to_markdown
)
from .metric_calculators import _calcular_metricas_agregadas_y_estabilidad, _calculate_stability_pct # NÃ³tese el .
from config import numeric_internal_cols # Importar desde la raÃ­z del proyecto
from utils import aggregate_strings

def _clean_audience_string(aud_str):
    """Remove numeric prefixes and commas from audience names.

    Audience strings may contain multiple audiences separated by either
    ``|`` or `,`. Commas inside the actual audience names can lead to
    confusion when several audiences are joined together. This helper
    normalizes the string by:

    1. Splitting on ``|`` or `,` to detect individual audiences.
    2. Removing any leading numeric identifiers (``123:Name`` -> ``Name``).
    3. Stripping commas from within each audience name.
    4. Joining the cleaned parts using a comma so the output uses ``","``
       only as a separator between distinct audience names.
    """
    if aud_str is None or str(aud_str).strip() == "-":
        return "-"

    text = str(aud_str)
    # Insert a separator before each new audience detected by the pattern
    # ``digits:`` when preceded by whitespace. This allows splitting on the
    # separator regardless of whether the original string used commas, pipes or
    # just spaces between audiences.
    text = re.sub(r"(?<=\s)(?=\d+\s*:)", "|", text)

    parts = re.split(r"\s*[|,]\s*", text)
    cleaned = []
    for p in parts:
        if not p:
            continue
        name = re.sub(r"^\s*\d+\s*:\s*", "", p).strip()
        name = name.replace(",", "").replace("|", "")
        if name:
            cleaned.append(name)

    return ", ".join(cleaned)


def _remove_commas(text):
    """Utility to strip commas from campaign, adset and ad names."""
    if text is None:
        return ""
    return str(text).replace(",", "")


# Metric labels used in the Top tables
METRIC_LABELS_BASE = [
    'ROAS', 'InversiÃ³n', 'Compras', 'Ventas', 'NCPA', 'CVR',
    'AOV', 'Alcance', 'Impresiones', 'CTR',
    'Presupuesto CampaÃ±a', 'Presupuesto Adset', 'Objetivo', 'Tipo Compra', 'Estado Entrega'
]
METRIC_LABELS_ADS = METRIC_LABELS_BASE + [
    'Frecuencia', 'RV25%', 'RV75%', 'RV100%', 'Tiempo RV (s)'
]


# ============================================================
# GENERACIÃ“N DE SECCIONES DEL REPORTE
# ============================================================


def _generar_tabla_vertical_global(df_daily_agg, detected_currency, log_func):
    """Build the summary table with global metrics and last month comparison."""

    log_func("\n\n============================================================"); log_func("===== 1. MÃ©tricas Globales y Comparativa Mensual ====="); log_func("============================================================")
    if df_daily_agg is None or df_daily_agg.empty or 'date' not in df_daily_agg.columns or df_daily_agg['date'].dropna().empty:
        log_func("\nNo hay datos agregados diarios o fechas vÃ¡lidas."); return

    global_metrics_current= _calcular_metricas_agregadas_y_estabilidad(df_daily_agg,'Global', log_func)
    global_days_count=df_daily_agg['date'].nunique() if not df_daily_agg.empty else 0

    previous_month_metrics=None; previous_month_label="-"; prev_month_date_range=""
    if relativedelta and date_parse and global_days_count>=28 and not df_daily_agg.empty:
        latest_date=df_daily_agg['date'].max(); earliest_date_val=df_daily_agg['date'].min();
        found_current_complete_month=False
        current_check_month_start_dt=(latest_date.replace(day=1)-relativedelta(months=1))
        log_func(f"  Buscando mes completo para comparar (datos: {earliest_date_val.strftime('%d/%m/%y')} - {latest_date.strftime('%d/%m/%y')})...")
        while current_check_month_start_dt.date()>=earliest_date_val.date().replace(day=1):
            current_month_end_dt=current_check_month_start_dt+relativedelta(months=1)-timedelta(days=1)
            log_func(f"    Probando mes: {current_check_month_start_dt.strftime('%Y-%m')}")
            if current_month_end_dt.date()<=latest_date.date() and current_check_month_start_dt.date() >= earliest_date_val.date():
                df_month_subset=df_daily_agg[(df_daily_agg['date'].dt.date>=current_check_month_start_dt.date())&(df_daily_agg['date'].dt.date<=current_month_end_dt.date())].copy();
                actual_days_in_calendar_month=(current_month_end_dt.date()-current_check_month_start_dt.date()).days+1;
                unique_days_in_month_data=df_month_subset['date'].nunique() if not df_month_subset.empty else 0
                if unique_days_in_month_data==actual_days_in_calendar_month:
                    log_func(f"      -> Mes completo encontrado: {current_check_month_start_dt.strftime('%Y-%m')} (serÃ¡ 'Mes Anterior')");
                    previous_month_metrics=_calcular_metricas_agregadas_y_estabilidad(df_month_subset,(current_check_month_start_dt.date(),current_month_end_dt.date()), log_func)
                    previous_month_label=f"Mes Ant. ({current_check_month_start_dt.strftime('%Y-%m')})";
                    prev_month_date_range=previous_month_metrics.get('date_range','')
                    found_current_complete_month = True
                    break
                else:
                    log_func(f"      -> Mes {current_check_month_start_dt.strftime('%Y-%m')} incompleto ({unique_days_in_month_data}/{actual_days_in_calendar_month} dÃ­as).")
            else:
                log_func(f"      -> Mes {current_check_month_start_dt.strftime('%Y-%m')} fuera del rango de datos o futuro.")
            current_check_month_start_dt-=relativedelta(months=1)
        if not found_current_complete_month: log_func("\nNo se encontrÃ³ un mes calendario completo anterior en los datos para comparaciÃ³n.")
    elif not (relativedelta and date_parse):
         log_func("\n'python-dateutil' no disponible, no se puede realizar comparaciÃ³n mensual.")
    else:
         log_func(f"\nDatos insuficientes ({global_days_count} dÃ­as Ãºnicos < 28) para comparaciÃ³n mensual significativa.")

    stability_keys=['ROAS_Stability_%','CPA_Stability_%','CPM_Stability_%','CTR_Stability_%','IMPR_Stability_%','CTR_DIV_FREQ_RATIO_Stability_%']
    metric_map={'Inversion Total':{'key':'Inversion','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}"},'Ventas Totales':{'key':'Ventas_Totales','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}"},'ROAS Promedio':{'key':'ROAS','formatter':lambda x: f"{fmt_float(x,2)}x"},'Compras Total':{'key':'Compras','formatter':fmt_int},'CPA Promedio':{'key':'CPA','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}"},'Ticket Promedio':{'key':'Ticket_Promedio','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}"},'Impresiones Total':{'key':'Impresiones','formatter':fmt_int},'Alcance Total':{'key':'Alcance','formatter':fmt_int},'Frecuencia Promedio':{'key':'Frecuencia','formatter':lambda x: fmt_float(x,2)},'CPM Promedio':{'key':'CPM','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}"},'Clics Total':{'key':'Clics','formatter':fmt_int},'CTR Promedio (%)':{'key':'CTR','formatter':lambda x: fmt_pct(x,2)},'Visitas Total':{'key':'Visitas','formatter':fmt_int},'Tasa Visita LP (%)':{'key':'LVP_Rate_%','formatter':lambda x: fmt_pct(x,1)},'Tasa Compra (%)':{'key':'Conv_Rate_%','formatter':lambda x: fmt_pct(x,1)},'Estabilidad ROAS (%)':{'key':'ROAS_Stability_%','formatter':fmt_stability},'Estabilidad CPA (%)':{'key':'CPA_Stability_%','formatter':fmt_stability},'Estabilidad CPM (%)':{'key':'CPM_Stability_%','formatter':fmt_stability},'Estabilidad CTR (%)':{'key':'CTR_Stability_%','formatter':fmt_stability},'Estabilidad Impr (%)':{'key':'IMPR_Stability_%','formatter':fmt_stability},'Estabilidad CTR/Freq (%)':{'key':'CTR_DIV_FREQ_RATIO_Stability_%','formatter':fmt_stability}}
    order=['Inversion Total','Ventas Totales','ROAS Promedio','Compras Total','CPA Promedio','Ticket Promedio','Impresiones Total','Alcance Total','Frecuencia Promedio','CPM Promedio','Clics Total','CTR Promedio (%)','Visitas Total','Tasa Visita LP (%)','Tasa Compra (%)','Estabilidad ROAS (%)','Estabilidad CPA (%)','Estabilidad CPM (%)','Estabilidad CTR (%)','Estabilidad Impr (%)','Estabilidad CTR/Freq (%)']
    headers=["Metrica",f"Global ({global_days_count} Dias)"];
    if previous_month_metrics: headers.append(previous_month_label)
    rows=[]
    for disp_name in order:
        info=metric_map.get(disp_name);
        if not info: continue
        key_m=info['key']; fmt=info['formatter']; row=[disp_name]; is_stab='Stability' in key_m
        curr_raw=global_metrics_current.get(key_m,np.nan); disp_curr='-' if (is_stab and not global_metrics_current.get('is_complete',False)) else (fmt(curr_raw) if pd.notna(curr_raw) else '-')
        row.append(disp_curr)
        if previous_month_metrics:
            prev_raw=previous_month_metrics.get(key_m,np.nan); disp_prev='-' if (is_stab and not previous_month_metrics.get('is_complete',False)) else (fmt(prev_raw) if pd.notna(prev_raw) else '-')
            if not is_stab:
                 var_val=variation(curr_raw,prev_raw);
                 row[1]=f"{disp_curr} ({var_val})" if var_val!='-' else disp_curr
            row.append(disp_prev)
        rows.append(row)
    df_disp=pd.DataFrame(rows,columns=headers)
    _format_dataframe_to_markdown(df_disp,"",log_func,currency_cols=detected_currency, stability_cols=stability_keys,numeric_cols_for_alignment=[h for h in headers if h!="Metrica"])
    log_func("\n  **Detalle de MÃ©tricas (Global):**");
    log_func(f"  * **Global ({global_days_count} Dias):** MÃ©tricas totales (sumas) o promedios/tasas de toda la cuenta para el perÃ­odo completo de datos ({global_metrics_current.get('date_range','desc.')}).")
    if previous_month_metrics:
        log_func(f"  * **{previous_month_label}:** MÃ©tricas del mes calendario completo anterior encontrado en los datos ({prev_month_date_range}).")
        log_func(f"  * **Valor en parÃ©ntesis (...) en Global:** VariaciÃ³n porcentual de las MÃ©tricas Globales comparadas con el Mes Anterior Completo. Una flecha ðŸ”º indica mejora, ðŸ”» indica empeoramiento respecto al mes anterior.")
    else: log_func("  * **Mes Ant.:** No se encontrÃ³ un mes anterior completo en los datos para comparaciÃ³n.")
    log_func("  * **Estabilidad (%):** Mide la consistencia de la mÃ©trica diaria dentro del perÃ­odo total. Un % alto indica que la mÃ©trica fue estable dÃ­a a dÃ­a. Calculada si el perÃ­odo tiene al menos 7 dÃ­as con datos y cumple umbrales mÃ­nimos. Iconos: âœ… >= 50%, ðŸ† >= 70%. '-' si no aplica o datos insuficientes.");
    log_func("  ---")




def _generar_tabla_vertical_entidad(entity_level, entity_name, dias_activos_total, df_daily_entity,
                                    min_entity_dt, max_entity_dt, adset_count,
                                    periods, detected_currency, log_func, period_type="Days"):
    """Generate the vertical metrics table for a specific campaign/ad/adset."""


    header_label=entity_level.capitalize(); date_range_str=f"({min_entity_dt.strftime('%d/%m/%y')} - {max_entity_dt.strftime('%d/%m/%y')})" if min_entity_dt and max_entity_dt else ""; adset_count_str=f"(AdSets: {adset_count}) " if entity_level.lower()=='campaÃ±a' and adset_count is not None else ""
    log_func(f"\n\n--------------------------------------------------------------------------------"); log_func(f" {header_label}: {entity_name} {adset_count_str}{date_range_str} (DÃ­as Activo Total: {fmt_int(dias_activos_total)})"); log_func(f"--------------------------------------------------------------------------------")
    if df_daily_entity is None or df_daily_entity.empty: log_func("   No hay datos diarios."); return

    global_metrics_raw=_calcular_metricas_agregadas_y_estabilidad(df_daily_entity,'Global', log_func);
    global_days_count=df_daily_entity['date'].nunique() if not df_daily_entity.empty else 0

    results_by_period={}
    period_labels = [] 
    period_details_local = [] 

    if period_type == "Days":
         log_func("  Calculando mÃ©tricas para perÃ­odos U... Dias...");
         periods_numeric = periods 
         for p_days in periods_numeric:
             p_label=f"U{p_days} Dias"; 
             start_date_p=max(max_entity_dt-timedelta(days=p_days-1),min_entity_dt)
             df_period_subset=df_daily_entity[(df_daily_entity['date']>=start_date_p)&(df_daily_entity['date']<=max_entity_dt)].copy();
             results_by_period[p_label]=_calcular_metricas_agregadas_y_estabilidad(df_period_subset,p_days, log_func)
             period_labels.append(p_label)
             period_details_local.append((start_date_p, max_entity_dt, p_label)) 
    elif period_type in ["Weeks", "Months", "Biweekly"]:
         log_func(f"  Calculando mÃ©tricas para perÃ­odos {period_type}...");
         period_details_local = periods 
         for start_dt, end_dt, label_from_orchestrator in period_details_local:
              df_period_subset = df_daily_entity[
                  (df_daily_entity['date'] >= start_dt) &
                  (df_daily_entity['date'] <= end_dt)
              ].copy();
              period_identifier_tuple = (start_dt.date(), end_dt.date()) 
              results_by_period[label_from_orchestrator] = _calcular_metricas_agregadas_y_estabilidad(df_period_subset, period_identifier_tuple, log_func)
              period_labels.append(label_from_orchestrator) 
              
    global_daily_avg={}; global_rates={}
    if period_type == "Days" and global_metrics_raw and global_days_count>0:
        sum_keys=['Alcance','Impresiones','Inversion','Ventas_Totales','Compras','Clics','Visitas']; rate_keys=['Frecuencia','CPM','CPA','CTR','ROAS','Ticket_Promedio','LVP_Rate_%','Conv_Rate_%']
        for key_s in sum_keys: global_daily_avg[key_s]=safe_division(global_metrics_raw.get(key_s,np.nan),global_days_count)
        for key_r in rate_keys: global_rates[key_r]=global_metrics_raw.get(key_r,np.nan)

    u7_inversion_adset = np.nan; u7_roas_adset = np.nan; prev_7_day_inversion_adset = np.nan; prev_7_day_roas_adset = np.nan; estado_inversion_roas_str = "-"
    results_prev_30 = None 

    if entity_level.lower() == 'adset' and period_type == "Days" and 7 in periods: 
         u7_label = "U7 Dias" 
         if u7_label in results_by_period:
             u7_results = results_by_period[u7_label]
             u7_inversion_adset = u7_results.get('Inversion', np.nan)
             u7_roas_adset = u7_results.get('ROAS', np.nan)

             u7_period_dates_tuple = next(((s,e,l) for s,e,l in period_details_local if l == u7_label), None)
             if u7_period_dates_tuple:
                 u7_start_dt_obj, u7_end_dt_obj, _ = u7_period_dates_tuple 
                 end_prev_7d_obj = u7_start_dt_obj - timedelta(days=1) 
                 start_prev_7d_obj = max(end_prev_7d_obj - timedelta(days=6), min_entity_dt) 

                 if start_prev_7d_obj <= end_prev_7d_obj: 
                     df_prev_7d_subset = df_daily_entity[
                         (df_daily_entity['date'] >= start_prev_7d_obj) &
                         (df_daily_entity['date'] <= end_prev_7d_obj)
                     ].copy();
                     prev_7_days_count = df_prev_7d_subset['date'].nunique()
                     is_prev_7_complete = (prev_7_days_count == 7) 

                     if not df_prev_7d_subset.empty and is_prev_7_complete:
                         metrics_prev_7d = _calcular_metricas_agregadas_y_estabilidad(df_prev_7d_subset, 7, log_func)
                         prev_7_day_inversion_adset = metrics_prev_7d.get('Inversion', np.nan)
                         prev_7_day_roas_adset = metrics_prev_7d.get('ROAS', np.nan)
                         log_func(f"    -> MÃ©tricas Prev 7 DÃ­as ({start_prev_7d_obj.strftime('%d/%m')}-{end_prev_7d_obj.strftime('%d/%m')}) calculadas (Completas: {is_prev_7_complete}).")
                     else:
                          log_func(f"    -> PerÃ­odo Prev 7 DÃ­as ({start_prev_7d_obj.strftime('%d/%m')}-{end_prev_7d_obj.strftime('%d/%m')}) incompleto ({prev_7_days_count} dÃ­as) o sin datos. No se usarÃ¡ para comparaciÃ³n directa de estado.")

         if pd.isna(prev_7_day_inversion_adset) and global_metrics_raw and global_days_count > 0:
            if pd.notna(u7_inversion_adset) and u7_inversion_adset > 0 or \
               (u7_label in results_by_period and results_by_period[u7_label].get('Impresiones', 0) > 0):
                 log_func("    -> Usando Promedio Diario Global (de esta entidad) x 7 como referencia para Prev 7 DÃ­as (para estado).")
                 prev_7_day_inversion_adset = global_daily_avg.get('Inversion', np.nan) * 7 if pd.notna(global_daily_avg.get('Inversion')) else np.nan
                 prev_7_day_roas_adset = global_rates.get('ROAS', np.nan) 

         if pd.notna(u7_inversion_adset) or (u7_label in results_by_period and pd.notna(results_by_period[u7_label].get('Impresiones'))): 
            if pd.notna(u7_inversion_adset) and pd.notna(prev_7_day_inversion_adset) and pd.notna(u7_roas_adset) and pd.notna(prev_7_day_roas_adset):
                inversion_change_pct = 0
                if abs(prev_7_day_inversion_adset) > 1e-9: 
                    inversion_change_pct = ((u7_inversion_adset - prev_7_day_inversion_adset) / prev_7_day_inversion_adset) * 100

                roas_change_pct = 0
                if abs(prev_7_day_roas_adset) > 1e-9: 
                    roas_change_pct = ((u7_roas_adset - prev_7_day_roas_adset) / prev_7_day_roas_adset) * 100
                
                INVERSION_CHANGE_THRESHOLD_PCT = 10.0 
                ROAS_DROP_TOLERANCE_RATIO = 0.5 
                ROAS_CHANGE_THRESHOLD_PCT = 5.0 

                if inversion_change_pct > INVERSION_CHANGE_THRESHOLD_PCT: 
                    if roas_change_pct >= -ROAS_CHANGE_THRESHOLD_PCT: estado_inversion_roas_str = "Positivo ðŸŸ¢ (â†‘Inv, >=ROAS)"
                    elif abs(roas_change_pct) <= abs(inversion_change_pct * ROAS_DROP_TOLERANCE_RATIO): estado_inversion_roas_str = "Estable ðŸŸ¡ (â†‘Inv, ~ROAS)"
                    else: estado_inversion_roas_str = "Negativo ðŸ”´ (â†‘Inv, â†“â†“ROAS)"
                elif inversion_change_pct < -INVERSION_CHANGE_THRESHOLD_PCT: 
                    if roas_change_pct >= -ROAS_CHANGE_THRESHOLD_PCT: estado_inversion_roas_str = "Estable ðŸŸ¡ (â†“Inv, >=ROAS)"
                    else: estado_inversion_roas_str = "PrecauciÃ³n ðŸŸ  (â†“Inv, â†“ROAS)"
                else: 
                    if roas_change_pct > ROAS_CHANGE_THRESHOLD_PCT: estado_inversion_roas_str = "Positivo ðŸŸ¢ (~Inv, â†‘ROAS)"
                    elif roas_change_pct < -ROAS_CHANGE_THRESHOLD_PCT: estado_inversion_roas_str = "PrecauciÃ³n ðŸŸ  (~Inv, â†“ROAS)"
                    else: estado_inversion_roas_str = "Estable ðŸŸ¡ (~Inv, ~ROAS)"
            else:
                 estado_inversion_roas_str = "Datos Insuficientes U7/Prev7"
    
    if period_type == "Days" and global_days_count >= 60 and relativedelta is not None and 30 in periods and 'U30 Dias' in results_by_period:
        u30_res = results_by_period['U30 Dias']
        if u30_res and u30_res.get('is_complete'): 
            u30_dates_tuple = next(((s,e,l) for s,e,l in period_details_local if l == 'U30 Dias'), None)
            if u30_dates_tuple:
                u30_start_dt_obj, _, _ = u30_dates_tuple 
                prev_30_end_dt_obj = u30_start_dt_obj - timedelta(days=1)
                prev_30_start_dt_obj = max(prev_30_end_dt_obj - timedelta(days=29), min_entity_dt)
                if prev_30_start_dt_obj <= prev_30_end_dt_obj: 
                    df_prev_30_subset = df_daily_entity[
                        (df_daily_entity['date'] >= prev_30_start_dt_obj) &
                        (df_daily_entity['date'] <= prev_30_end_dt_obj)
                    ].copy()
                    results_prev_30 = _calcular_metricas_agregadas_y_estabilidad(df_prev_30_subset, (prev_30_start_dt_obj.date(), prev_30_end_dt_obj.date()), log_func)
                    if results_prev_30 and results_prev_30.get('is_complete'):
                        log_func(f"    -> MÃ©tricas Prev 30 DÃ­as ({results_prev_30.get('date_range')}) calculadas para comparaciÃ³n U30.")

    metric_map_base_rendimiento={
        'Inversion Total':{'key':'Inversion','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}",'type':'sum', 'display':'Inversion Total'},
        'Ventas Totales':{'key':'Ventas_Totales','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}",'type':'sum', 'display':'Ventas Totales'},
        'ROAS Promedio':{'key':'ROAS','formatter':lambda x: f"{fmt_float(x,2)}x",'type':'rate', 'display':'ROAS Promedio'},
        'Compras Total':{'key':'Compras','formatter':fmt_int,'type':'sum', 'display':'Compras Total'},
        'CPA Promedio':{'key':'CPA','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}",'type':'rate', 'display':'CPA Promedio'},
        'Ticket Promedio':{'key':'Ticket_Promedio','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}",'type':'rate', 'display':'Ticket Promedio'},
        'Impresiones Total':{'key':'Impresiones','formatter':fmt_int,'type':'sum', 'display':'Impresiones Total'},
        'Alcance Total':{'key':'Alcance','formatter':fmt_int,'type':'sum', 'display':'Alcance Total'},
        'Frecuencia Promedio':{'key':'Frecuencia','formatter':lambda x: fmt_float(x,2),'type':'rate', 'display':'Frecuencia Promedio'},
        'CPM Promedio':{'key':'CPM','formatter':lambda x: f"{detected_currency}{fmt_float(x,2)}",'type':'rate', 'display':'CPM Promedio'},
        'Clics Total':{'key':'Clics','formatter':fmt_int,'type':'sum', 'display':'Clics Total'},
        'CTR Promedio (%)':{'key':'CTR','formatter':lambda x: fmt_pct(x,2),'type':'rate', 'display':'CTR Promedio (%)'},
        'Visitas Total':{'key':'Visitas','formatter':fmt_int,'type':'sum', 'display':'Visitas Total'},
        'Tasa Visita LP (%)':{'key':'LVP_Rate_%','formatter':lambda x: fmt_pct(x,1),'type':'rate', 'display':'Tasa Visita LP (%)'},
        'Tasa Compra (%)':{'key':'Conv_Rate_%','formatter':lambda x: fmt_pct(x,1),'type':'rate', 'display':'Tasa Compra (%)'}
    }
    
    metric_map_video_rendimiento = {} 
    if not (entity_level.lower() in ['campaÃ±a', 'adset'] and period_type == "Days"):
        metric_map_video_rendimiento = {
            'Tiempo Promedio RV (s)':{'key':'Tiempo_Promedio','formatter':lambda x: fmt_float(x,1),'type':'rate', 'display':'Tiempo Promedio RV (s)'},
            'RV25 (%)':{'key':'RV25_%','formatter':lambda x: fmt_pct(x,1),'type':'rate', 'display':'RV25 (%)'},
            'RV75 (%)':{'key':'RV75_%','formatter':lambda x: fmt_pct(x,1),'type':'rate', 'display':'RV75 (%)'},
            'RV100 (%)':{'key':'RV100_%','formatter':lambda x: fmt_pct(x,1),'type':'rate', 'display':'RV100 (%)'}
        }
    
    current_metric_map_base = {**metric_map_base_rendimiento, **metric_map_video_rendimiento}

    metric_map_stability = {'Estabilidad ROAS (%)':{'key':'ROAS_Stability_%','formatter':fmt_stability,'type':'stability', 'display':'Estabilidad ROAS (%)'},'Estabilidad CPA (%)':{'key':'CPA_Stability_%','formatter':fmt_stability,'type':'stability', 'display':'Estabilidad CPA (%)'},'Estabilidad CPM (%)':{'key':'CPM_Stability_%','formatter':fmt_stability,'type':'stability', 'display':'Estabilidad CPM (%)'},'Estabilidad CTR (%)':{'key':'CTR_Stability_%','formatter':fmt_stability,'type':'stability', 'display':'Estabilidad CTR (%)'},'Estabilidad Impr (%)':{'key':'IMPR_Stability_%','formatter':fmt_stability,'type':'stability', 'display':'Estabilidad Impr (%)'},'Estabilidad CTR/Freq (%)':{'key':'CTR_DIV_FREQ_RATIO_Stability_%','formatter':fmt_stability,'type':'stability', 'display':'Estabilidad CTR/Freq (%)'}}
    
    metric_map = { v['key']: v for v in list(current_metric_map_base.values()) + list(metric_map_stability.values())} 
    
    order_display_names_base=[ 
        'Inversion Total', 'CPM Promedio', 'Impresiones Total', 'Alcance Total', 'Frecuencia Promedio',
        'Clics Total', 'CTR Promedio (%)', 'Visitas Total', 'Tasa Visita LP (%)',
        'Compras Total', 'Tasa Compra (%)', 'Ventas Totales', 'CPA Promedio', 'Ticket Promedio', 'ROAS Promedio'
    ]
    order_display_names_video = []
    if not (entity_level.lower() in ['campaÃ±a', 'adset'] and period_type == "Days"):
        order_display_names_video = ['Tiempo Promedio RV (s)', 'RV25 (%)', 'RV75 (%)', 'RV100 (%)']

    order_display_names_stability = [ 
        'Estabilidad ROAS (%)', 'Estabilidad CPA (%)', 'Estabilidad CPM (%)', 'Estabilidad CTR (%)', 'Estabilidad Impr (%)', 'Estabilidad CTR/Freq (%)'
    ]
    order_display_names = order_display_names_base + order_display_names_video + order_display_names_stability

    headers=["Metrica"] + period_labels 
    can_compare_30d_vertical = False 
    if period_type == "Days" and global_days_count>=60 and relativedelta is not None and 30 in periods: 
        if results_prev_30 and results_prev_30.get('is_complete'): 
            can_compare_30d_vertical=True
            if "Prev 30 Dias" not in headers: headers.append("Prev 30 Dias") 

    rows=[]
    for disp_name_order in order_display_names: 
        internal_key = None
        for k_map, v_map in metric_map.items(): 
            if v_map.get('display') == disp_name_order:
                internal_key = k_map 
                break
        
        if not internal_key: 
            continue

        info = metric_map.get(internal_key) 
        if not info: 
            print(f"Advertencia: No se encontrÃ³ informaciÃ³n para la mÃ©trica clave '{internal_key}' en metric_map.")
            continue

        key_m=info['key']; fmt=info['formatter']; mtype=info['type']; row=[disp_name_order]; glob_comp=np.nan

        if period_type == "Days" and global_metrics_raw:
            if mtype=='sum': glob_comp=global_daily_avg.get(key_m,np.nan)
            elif mtype=='rate': glob_comp=global_rates.get(key_m,np.nan)

        for p_label in period_labels: 
             p_res=results_by_period.get(p_label) 
             curr_raw=p_res.get(key_m,np.nan) if p_res is not None else np.nan 
             fmt_val=fmt(curr_raw) if pd.notna(curr_raw) else '-' 
             var_fmt='-' 

             if period_type == "Days" and mtype!='stability' and pd.notna(glob_comp) and pd.notna(curr_raw):
                 p_days_val_search = re.search(r'U(\d+) Dias', p_label)
                 if p_days_val_search:
                     p_days_val = int(p_days_val_search.group(1))
                     p_dates_tuple = next(((s,e,l) for s,e,l in period_details_local if l == p_label), None)
                     act_days = 0
                     if p_dates_tuple:
                        p_start_dt_obj, p_end_dt_obj, _ = p_dates_tuple
                        p_df_temp=df_daily_entity[(df_daily_entity['date']>=p_start_dt_obj)&(df_daily_entity['date']<=p_end_dt_obj)].copy()
                        act_days=p_df_temp['date'].nunique() if not p_df_temp.empty else 0

                     comp_val=np.nan 
                     if mtype=='sum': comp_val=glob_comp*act_days if act_days>0 else np.nan 
                     elif mtype=='rate': comp_val=glob_comp 
                     if pd.notna(comp_val): var_fmt=variation(curr_raw,comp_val) 
             
             disp_val=f"{fmt_val} ({var_fmt})" if period_type == "Days" and mtype!='stability' and var_fmt!='-' and fmt_val!='-' else fmt_val
             if mtype=='stability' and (p_res is None or not p_res.get('is_complete',False)): disp_val='-' 
             row.append(disp_val)

        if period_type == "Days" and can_compare_30d_vertical: 
            prev30_raw=results_prev_30.get(key_m,np.nan) if results_prev_30 is not None else np.nan
            fmt_p30=fmt(prev30_raw) if pd.notna(prev30_raw) else '-'

            if "U30 Dias" in period_labels: 
                u30_index_in_row = period_labels.index("U30 Dias") + 1 
                if u30_index_in_row < len(row): 
                    u30_raw=results_by_period.get("U30 Dias",{}).get(key_m,np.nan)
                    var_vs_l30=variation(u30_raw,prev30_raw) 
                    u30_fmt_val = fmt(u30_raw) if pd.notna(u30_raw) else '-'
                    u30_comp_str = f" ({var_vs_l30})" if var_vs_l30 != '-' else ""
                    u30_disp_val = f"{u30_fmt_val}{u30_comp_str}" if mtype!='stability' and u30_fmt_val != '-' else u30_fmt_val
                    
                    if mtype=='stability' and (results_by_period.get("U30 Dias") is None or not results_by_period.get("U30 Dias",{}).get('is_complete',False)): u30_disp_val='-'
                    row[u30_index_in_row] = u30_disp_val 
            
            disp_p30=fmt_p30 
            if mtype=='stability' and (results_prev_30 is None or not results_prev_30.get('is_complete',False)): disp_p30='-'
            row.append(disp_p30) 
        rows.append(row)

    if entity_level.lower() == 'adset' and period_type == "Days" and estado_inversion_roas_str != "-":
        row_estado_display = ["Estado InversiÃ³n/ROAS (U7D)"]
        u7_col_index = next((i for i, label in enumerate(period_labels) if label == "U7 Dias"), None) 
        if u7_col_index is not None:
             placeholders_needed = len(headers) - 1 
             full_row_estado = ["-"] * placeholders_needed 
             full_row_estado[u7_col_index] = estado_inversion_roas_str 
             row_estado_display.extend(full_row_estado)
        
        if len(row_estado_display) == len(headers): 
             rows.append(row_estado_display)
        elif estado_inversion_roas_str != "-": 
             log_func("Adv: No se pudo alinear la fila 'Estado InversiÃ³n/ROAS (U7D)' con las columnas de perÃ­odo. Omitiendo.")

    df_disp = pd.DataFrame(rows, columns=headers)
    numeric_cols_for_alignment = [h for h in headers if h != "Metrica" and "Estado InversiÃ³n/ROAS (U7D)" not in h] 
    stability_cols_display = [v['display'] for k,v in metric_map.items() if 'Stability' in k] 
    _format_dataframe_to_markdown(df_disp, "", log_func, currency_cols=detected_currency,
                                  stability_cols=stability_cols_display, 
                                  numeric_cols_for_alignment=numeric_cols_for_alignment)

    log_func("\n  **Detalle de MÃ©tricas de Rendimiento por Entidad:**");
    if period_type == "Days":
         log_func("  * **UX Dias:** MÃ©tricas acumuladas (sumas) o promedios/tasas para los Ãºltimos X dÃ­as indicados, especÃ­ficas para esta entidad.")
         log_func("  * **Valor en parÃ©ntesis (...) en UX Dias:** Compara el valor del perÃ­odo UX DÃ­as contra el promedio diario histÃ³rico de *esta entidad* (proyectado para X dÃ­as si es una suma, o directo si es una tasa/promedio). Una flecha ðŸ”º indica mejora, ðŸ”» indica empeoramiento respecto al histÃ³rico de la entidad. Ayuda a ver si el rendimiento reciente es mejor o peor que su histÃ³rico.")
         if can_compare_30d_vertical: log_func("  * **Col 'Prev 30 Dias':** Valor para los 30 dÃ­as anteriores al perÃ­odo 'U30 Dias'. **(...)** en 'U30 Dias' es la variaciÃ³n de U30 vs Prev 30 Dias para esta entidad.")
    elif period_type == "Weeks":
         log_func("  * **Columnas (Semana actual, XÂª semana anterior):** Muestran las mÃ©tricas acumuladas (sumas) o promedios/tasas para cada semana definida (Actual a mÃ¡s antigua, de izq. a der.), especÃ­ficas para esta entidad.")
         log_func("  * **Valor en parÃ©ntesis (...) en columnas Semanales:** Compara el valor de esa semana con la semana *inmediatamente anterior* mostrada (la columna a su derecha). Muestra la variaciÃ³n porcentual semana a semana (WoW). Una flecha ðŸ”º indica mejora, ðŸ”» indica empeoramiento respecto a la semana anterior.")
    elif period_type == "Biweekly":
         log_func("  * **Columnas (Quincena actual, XÂª quincena anterior):** Muestran las mÃ©tricas acumuladas o promedios para cada quincena definida, especÃ­ficas para esta entidad.")
         log_func("  * **Valor en parÃ©ntesis (...) en columnas Quincenales:** Compara el valor de esa quincena con la inmediatamente anterior. Indica la variaciÃ³n quincenal.")
    elif period_type == "Months":
         log_func("  * **Columnas (Mes Actual, Mes Ant. 1):** Muestran las mÃ©tricas acumuladas (sumas) o promedios/tasas para los 2 Ãºltimos meses calendario completos detectados, especÃ­ficas para esta entidad.")
         log_func("  * **Valor en parÃ©ntesis (...) en 'Mes Actual':** Compara el valor del Mes Actual con el Mes Anterior mostrado. Muestra la variaciÃ³n porcentual mes a mes (MoM). Una flecha ðŸ”º indica mejora, ðŸ”» indica empeoramiento respecto al mes anterior.")

    log_func("  * **Estabilidad (%):** Mide la consistencia diaria *dentro* del perÃ­odo indicado. Un % alto indica que la mÃ©trica fue estable dÃ­a a dÃ­a. Se calcula si el perÃ­odo tiene todos sus dÃ­as con datos y cumple umbrales mÃ­nimos. Iconos: âœ… >= 50%, ðŸ† >= 70%.")

    if entity_level.lower() == 'adset' and period_type == "Days":
        log_func("  * **Estado InversiÃ³n/ROAS (U7D):** (Solo para AdSets) EvalÃºa cambio en inversiÃ³n y ROAS en U7D vs los 7 dÃ­as anteriores (o vs promedio global si no hay datos previos suficientes):")
        log_func("    - **Positivo ðŸŸ¢:** â†‘InversiÃ³n con ROAS igual/mejor O â‰ˆInversiÃ³n con â†‘ROAS.")
        log_func("    - **Estable ðŸŸ¡:** â†‘InversiÃ³n con leve caÃ­da ROAS O â†“InversiÃ³n con ROAS igual/mejor O â‰ˆInversiÃ³n y â‰ˆROAS.")
        log_func("    - **PrecauciÃ³n ðŸŸ :** â†“InversiÃ³n con â†“ROAS O â‰ˆInversiÃ³n con â†“ROAS.")
        log_func("    - **Negativo ðŸ”´:** â†‘InversiÃ³n con caÃ­da significativa de ROAS.")
    log_func("  ---")


def _generar_tabla_embudo_rendimiento(df_daily_agg, periods_numeric, log_func, detected_currency):
    """Create funnel analysis table comparing periods against projected averages."""

    log_func("\n\n============================================================");log_func("===== 4. AnÃ¡lisis de Embudo por PerÃ­odo (vs Promedio U30 Proyectado) =====");log_func("============================================================")
    funnel_steps_config=[ 
        ('Impresiones','impr'),
        ('Clics (Enlace)','clicks'),
        ('Clics Salientes','clicks_out'),
        ('Visitas LP','visits'),
        ('AtenciÃ³n (Hook)','attention'), 
        ('InterÃ©s (Body)','interest'),
        ('Deseo (CTA)','deseo'),
        ('AÃ±adido al Carrito','addcart'),
        ('Inicio de Pago','checkout'),
        ('Compras','purchases')
    ]
    if df_daily_agg is None or df_daily_agg.empty or 'date' not in df_daily_agg.columns or df_daily_agg['date'].dropna().empty:
        log_func(f"\nNo hay datos o fechas vÃ¡lidas para embudo."); return

    available_internal_cols=[s[1] for s in funnel_steps_config if s[1] in df_daily_agg.columns] 
    funnel_steps_config_available=[s for s in funnel_steps_config if s[1] in available_internal_cols] 
    if not funnel_steps_config_available: log_func(f"\nNo hay columnas del embudo disponibles en los datos agregados."); return
    log_func(f"Columnas embudo disponibles: {[s[0] for s in funnel_steps_config_available]}")

    max_date_val=df_daily_agg['date'].max();min_data_date_val=df_daily_agg['date'].min()
    u30_start_val=max(max_date_val-timedelta(days=30-1),min_data_date_val) 
    df_u30_subset=df_daily_agg[(df_daily_agg['date']>=u30_start_val)&(df_daily_agg['date']<=max_date_val)].copy();
    u30_sums=df_u30_subset[available_internal_cols].sum(skipna=True);u30_actual_days=df_u30_subset['date'].nunique()
    u30_daily_avg=safe_division(u30_sums,u30_actual_days) if u30_actual_days>0 else pd.Series(0.0,index=u30_sums.index) 
    log_func(f"Promedio diario U30 para proyecciÃ³n basado en {u30_actual_days} dÃ­as reales.")

    period_sums={}; period_days={}
    for p_days in periods_numeric: 
        p_label=f"U{p_days}"; p_start_date=max(max_date_val-timedelta(days=p_days-1),min_data_date_val)
        if p_start_date <= max_date_val: 
             df_p_subset=df_daily_agg[(df_daily_agg['date']>=p_start_date)&(df_daily_agg['date']<=max_date_val)].copy();
             period_sums[p_label]=df_p_subset[available_internal_cols].sum(skipna=True) 
             period_days[p_label]=df_p_subset['date'].nunique() 
        else: 
             period_sums[p_label] = pd.Series(0.0, index=available_internal_cols)
             period_days[p_label] = 0

    headers=["Paso del Embudo"]; [headers.extend([f"U{p} (Proj)",f"% U{p}"]) for p in periods_numeric] 
    formatted_rows_data=[];last_step_total=pd.Series(np.nan,index=[f"U{p}" for p in periods_numeric]) 

    for idx, (disp_name,int_col) in enumerate(funnel_steps_config_available): 
        row_vals=[disp_name];u30_avg_val=u30_daily_avg.get(int_col,np.nan);curr_step_total=pd.Series(np.nan,index=[f"U{p}" for p in periods_numeric])
        for p_days in periods_numeric: 
            p_label=f"U{p_days}";actual_total=period_sums.get(p_label,{}).get(int_col,np.nan);actual_days=period_days.get(p_label,0)
            proj_val=u30_avg_val*actual_days if pd.notna(u30_avg_val) and actual_days>0 else np.nan 
            fmt_act=fmt_int(actual_total);fmt_proj=fmt_int(proj_val); proj_check='' 
            if pd.notna(actual_total) and pd.notna(proj_val) and abs(proj_val) > 1e-9 :
                diff_pct=abs(actual_total-proj_val)/abs(proj_val)*100;
                if diff_pct<=20.0: proj_check=' âœ…' 
            pct_vs_prev=np.nan 
            if idx > 0: 
                last_total_val=last_step_total.get(p_label,np.nan)
                if pd.notna(last_total_val) and last_total_val>0 and pd.notna(actual_total):
                     pct_vs_prev=safe_division(actual_total,last_total_val)*100 
            pct_prev_fmt=format_step_pct(pct_vs_prev) if idx > 0 else '-' 
            row_vals.append(f"{fmt_act} ({fmt_proj}){proj_check}"); row_vals.append(pct_prev_fmt); 
            curr_step_total[p_label]=actual_total if pd.notna(actual_total) else 0 
        formatted_rows_data.append(row_vals);last_step_total=curr_step_total.copy()

    df_temp_display=pd.DataFrame(formatted_rows_data,columns=headers) 
    _format_dataframe_to_markdown(df_temp_display,"",log_func,numeric_cols_for_alignment=[h for h in headers if h!="Paso del Embudo"]) 
    log_func("\n  **Detalle de MÃ©tricas (Embudo de Rendimiento):**");
    log_func("  * **Paso del Embudo:** Etapa del proceso de conversiÃ³n, desde la exposiciÃ³n inicial (Impresiones) hasta la acciÃ³n final (Compras). Los datos aquÃ­ son el total de la cuenta para cada paso.")
    log_func("  * **UX (Proj):** Muestra el valor *Real* acumulado para esa etapa en los Ãºltimos X dÃ­as. El valor entre parÃ©ntesis **(...)** es la *ProyecciÃ³n* de lo que se esperarÃ­a para ese paso, basada en el rendimiento promedio diario de los Ãºltimos 30 dÃ­as (U30) de toda la cuenta, ajustado a la cantidad de dÃ­as del perÃ­odo UX.")
    log_func("  * **âœ… (Checkmark):** Indica que el valor Real del paso estÃ¡ dentro de un +/-20% de su ProyecciÃ³n, sugiriendo un rendimiento acorde a lo esperado recientemente para toda la cuenta.")
    log_func("  * **% UX:** Es la tasa de conversiÃ³n o 'tasa de paso' de esta etapa con respecto a la etapa *anterior* en el embudo (ej. Clics/Impresiones). Muestra quÃ© porcentaje de usuarios avanzÃ³ de un paso al siguiente. La **Flecha (ðŸ”º/ðŸ”»)** indica si este porcentaje de paso es mayor o menor que el 100% (tasas menores son normales). '-' para el primer paso.")
    log_func("  * _Nota:_ La disponibilidad de pasos como Clics Salientes, AtenciÃ³n, InterÃ©s y Deseo depende de si estos datos estÃ¡n presentes en los archivos de origen."); log_func("  ---")



def _generar_tabla_embudo_bitacora(df_daily_agg, bitacora_periods_list, log_func, detected_currency, period_type="Weeks"):
    """Produce a detailed funnel table for a sequence of recent periods."""

    original_locale = locale.getlocale(locale.LC_TIME)
    try:
        locale_candidates = ['es_ES.UTF-8', 'es_ES', 'Spanish_Spain', 'Spanish']
        locale_set = False
        for loc_candidate in locale_candidates:
            try:
                locale.setlocale(locale.LC_TIME, loc_candidate)
                locale_set = True
                break
            except locale.Error:
                continue
        if not locale_set:
            log_func("Adv: No se pudo configurar el locale a espaÃ±ol para nombres de meses en embudo bitÃ¡cora. Se usarÃ¡n nombres en inglÃ©s por defecto.")
    except Exception as e_locale_set_embudo:
         log_func(f"Adv: Error al intentar configurar locale en embudo bitÃ¡cora: {e_locale_set_embudo}")


    log_func("\n\n============================================================")
    title_map = {"Weeks": "Semanal", "Months": "Mensual", "Biweekly": "Quincenal"}
    title_comp = title_map.get(period_type, period_type)
    log_func(f"===== AnÃ¡lisis de Embudo - Comparativa {title_comp} =====")
    log_func("============================================================")

    funnel_steps_config=[
        ('Impresiones','impr'), ('Clics (Enlace)','clicks'), ('Clics Salientes','clicks_out'),
        ('Visitas LP','visits'), ('AtenciÃ³n (Hook)','attention'), ('InterÃ©s (Body)','interest'),
        ('Deseo (CTA)','deseo'), ('AÃ±adido al Carrito','addcart'), ('Inicio de Pago','checkout'),
        ('Compras','purchases')
    ]
    if df_daily_agg is None or df_daily_agg.empty or 'date' not in df_daily_agg.columns or df_daily_agg['date'].dropna().empty:
        log_func(f"\nNo hay datos o fechas vÃ¡lidas para embudo de bitÃ¡cora."); return

    available_internal_cols=[s[1] for s in funnel_steps_config if s[1] in df_daily_agg.columns]
    funnel_steps_config_available=[s for s in funnel_steps_config if s[1] in available_internal_cols]
    if not funnel_steps_config_available: 
        log_func(f"\nNo hay columnas del embudo disponibles para bitÃ¡cora.") 
        df_temp_display = pd.DataFrame(columns=["Paso del Embudo"] + [f"PerÃ­odo {i+1}" for i in range(len(bitacora_periods_list))])
        _format_dataframe_to_markdown(df_temp_display,"",log_func,numeric_cols_for_alignment=[])
        try:
            locale.setlocale(locale.LC_TIME, original_locale)
        except locale.Error as loc_err:
            log_func(f"Adv: error restaurando locale: {loc_err}")
        return
    log_func(f"Columnas embudo disponibles: {[s[0] for s in funnel_steps_config_available]}")
    
    existing_numeric_cols_in_agg = [col for col in numeric_internal_cols if col in df_daily_agg.columns]
    if not existing_numeric_cols_in_agg:
         log_func("Adv: No se encontraron columnas numÃ©ricas para agregar en la bitÃ¡cora del embudo.");
         df_temp_display = pd.DataFrame(columns=["Paso del Embudo"] + [f"PerÃ­odo {i+1}" for i in range(len(bitacora_periods_list))])
         _format_dataframe_to_markdown(df_temp_display,"",log_func,numeric_cols_for_alignment=[])
         try:
             locale.setlocale(locale.LC_TIME, original_locale)
         except locale.Error as loc_err:
             log_func(f"Adv: error restaurando locale: {loc_err}")
         return

    df_daily_total_for_bitacora = df_daily_agg.groupby('date', as_index=False, observed=True)[existing_numeric_cols_in_agg].sum()
    s_tot=df_daily_total_for_bitacora.get('spend',pd.Series(np.nan,index=df_daily_total_for_bitacora.index));
    i_tot=df_daily_total_for_bitacora.get('impr',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    c_tot=df_daily_total_for_bitacora.get('clicks',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    co_tot=df_daily_total_for_bitacora.get('clicks_out',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    vi_tot=df_daily_total_for_bitacora.get('visits',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    p_tot=df_daily_total_for_bitacora.get('purchases',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    rv3_tot=df_daily_total_for_bitacora.get('rv3',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    rv25_tot=df_daily_total_for_bitacora.get('rv25',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    rv75_tot=df_daily_total_for_bitacora.get('rv75',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))
    rv100_tot=df_daily_total_for_bitacora.get('rv100',pd.Series(np.nan,index=df_daily_total_for_bitacora.index))


    df_daily_total_for_bitacora['ctr']=safe_division_pct(c_tot,i_tot)
    df_daily_total_for_bitacora['ctr_out'] = safe_division_pct(co_tot, i_tot)
    df_daily_total_for_bitacora['lpv_rate']=safe_division_pct(vi_tot,c_tot)
    df_daily_total_for_bitacora['purchase_rate']=safe_division_pct(p_tot,vi_tot)
    
    base_rv_tot = np.where(pd.Series(rv3_tot > 0).fillna(False), rv3_tot, i_tot)
    df_daily_total_for_bitacora['rv25_pct_daily'] = safe_division_pct(rv25_tot, base_rv_tot)
    df_daily_total_for_bitacora['rv75_pct_daily'] = safe_division_pct(rv75_tot, base_rv_tot)
    df_daily_total_for_bitacora['rv100_pct_daily'] = safe_division_pct(rv100_tot, base_rv_tot)

    period_sums = {}
    cols_to_sum_in_period = available_internal_cols + [c for c in ['ctr', 'ctr_out', 'lpv_rate', 'purchase_rate', 'rv25_pct_daily', 'rv75_pct_daily', 'rv100_pct_daily'] if c in df_daily_total_for_bitacora.columns]

    for start_dt, end_dt, original_label_from_list in bitacora_periods_list:
        df_p_subset = df_daily_total_for_bitacora[(df_daily_total_for_bitacora['date'] >= start_dt) & (df_daily_total_for_bitacora['date'] <= end_dt)].copy()
        period_sums[original_label_from_list] = df_p_subset[cols_to_sum_in_period].sum(skipna=True)

    headers_with_pct = ["Paso del Embudo"]
    for i, (start_dt_period, end_dt_period, period_label_formatted) in enumerate(bitacora_periods_list):
        headers_with_pct.append(period_label_formatted) 
        header_base_name = period_label_formatted.split(" (")[0] if " (" in period_label_formatted else period_label_formatted
        headers_with_pct.append(f"% Paso ({header_base_name})")


    formatted_rows_data=[]
    previous_step_totals = {p[2]: np.nan for p in bitacora_periods_list} 

    funnel_internal_cols_ordered = [s[1] for s in funnel_steps_config_available]
    funnel_display_names_ordered = [s[0] for s in funnel_steps_config_available]

    for idx_embudo, int_col_embudo in enumerate(funnel_internal_cols_ordered):
        disp_name_embudo = funnel_display_names_ordered[idx_embudo]
        row_vals = [disp_name_embudo]
        current_step_totals_for_this_embudo_step = {}

        for i_period, (_, _, original_period_label) in enumerate(bitacora_periods_list):
            actual_total_paso_embudo = period_sums.get(original_period_label, {}).get(int_col_embudo, np.nan)
            current_step_totals_for_this_embudo_step[original_period_label] = actual_total_paso_embudo if pd.notna(actual_total_paso_embudo) else 0
            
            fmt_act_total = fmt_int(actual_total_paso_embudo)
            row_vals.append(fmt_act_total) 

            pct_vs_prev_embudo_step = np.nan
            if idx_embudo > 0 and original_period_label in previous_step_totals:
                total_paso_anterior_embudo = previous_step_totals[original_period_label]
                if pd.notna(actual_total_paso_embudo) and pd.notna(total_paso_anterior_embudo) and abs(total_paso_anterior_embudo) > 1e-9:
                     pct_vs_prev_embudo_step = safe_division_pct(actual_total_paso_embudo, total_paso_anterior_embudo)
            
            pct_prev_fmt = str(format_step_pct(pct_vs_prev_embudo_step)) if pd.notna(pct_vs_prev_embudo_step) else '-'
            row_vals.append(pct_prev_fmt)
        
        formatted_rows_data.append(row_vals)
        previous_step_totals = current_step_totals_for_this_embudo_step

    if not formatted_rows_data:
        log_func("No se generaron datos para la tabla de embudo de bitÃ¡cora.")
    else:
        df_temp_display=pd.DataFrame(formatted_rows_data,columns=headers_with_pct)
        _format_dataframe_to_markdown(df_temp_display,"",log_func,numeric_cols_for_alignment=[h for h in headers_with_pct if h!="Paso del Embudo"])
    
    log_func("\n  **Detalle de MÃ©tricas (Embudo de BitÃ¡cora):**");
    log_func(f"  * **Paso del Embudo:** Etapa del proceso de conversiÃ³n (datos agregados de cuenta completa).")
    if period_type == 'Weeks':
        col_label = 'Semana actual, XÂª semana anterior'
        pct_label = 'Semana'
    elif period_type == 'Biweekly':
        col_label = 'Quincena actual, XÂª quincena anterior'
        pct_label = 'Quincena'
    else:
        col_label = 'Mes actual, XÂº mes anterior'
        pct_label = 'Mes'
    log_func(f"  * **Columnas ({col_label}):** Muestran el valor *Real* acumulado para esa etapa en el perÃ­odo indicado.")
    log_func(f"  * **% Paso ({pct_label}):** Es la tasa de conversiÃ³n de esta etapa con respecto a la etapa *anterior en el embudo* (ej. Clics/Impresiones) DENTRO DEL MISMO PERÃODO. La Flecha (ðŸ”º/ðŸ”») indica si este porcentaje de paso es mayor o menor que el 100%. '-' para el primer paso.");
    log_func("  ---")
    try:
        locale.setlocale(locale.LC_TIME, original_locale)
    except locale.Error as loc_err:
        log_func(f"Adv: error restaurando locale: {loc_err}")


def _generar_analisis_ads(df_combined, df_daily_agg, active_days_total_ad_df, log_func, detected_currency, last_day_status_lookup=None):
    """Generate consolidated report sections focused on individual ads."""

    log_func("\n\n============================================================");log_func("===== 5. AnÃ¡lisis Consolidado de ADS =====");log_func("=====     (Filtro: Ads con Gasto > 0, Impresiones > 0 Y DÃ­as Activos > 0) =====");log_func("============================================================")
    essential_cols=['Campaign','AdSet','Anuncio','date','spend','impr']; 
    if df_daily_agg is None or df_daily_agg.empty or not all(c_col in df_daily_agg.columns for c_col in essential_cols) or df_daily_agg['date'].dropna().empty:
        log_func("\nNo hay datos/columnas esenciales/fechas vÃ¡lidas para anÃ¡lisis ADS."); return
    group_cols_ad=['Campaign','AdSet','Anuncio']; active_days_cols=group_cols_ad+['DÃ­as_Activo_Total'] 
    if active_days_total_ad_df is None or active_days_total_ad_df.empty or not all(c_col in active_days_total_ad_df.columns for c_col in active_days_cols):
        log_func("Adv: Datos DÃ­as Activos no disponibles para Ads. Se asumirÃ¡ 0.");
        active_days_total_ad_df=pd.DataFrame(columns=active_days_cols) 

    df_daily_agg_copy = df_daily_agg.copy() 
    for col in group_cols_ad:
        if col in df_daily_agg_copy.columns:
             df_daily_agg_copy[col] = df_daily_agg_copy[col].astype(str)

    max_date_val=df_daily_agg_copy['date'].max(); min_data_date_val=df_daily_agg_copy['date'].min() 
    log_func("\nAgregando mÃ©tricas globales por Anuncio...", importante=True);
    agg_dict_base={
        'spend':'sum','value':'sum','purchases':'sum','clicks':'sum','clicks_out':'sum',
        'impr':'sum','reach':'sum','visits':'sum','rv3':'sum','rv25':'sum','rv75':'sum','rv100':'sum',
        'rtime':'mean','frequency':'mean','cpm':'mean','ctr':'mean','ctr_out':'mean',
        'roas':'mean','cpa':'mean',
        'rv25_pct':'mean','rv75_pct':'mean','rv100_pct':'mean',
        'PÃºblicos In':lambda x:aggregate_strings(x,separator=', ',max_len=None),
        'PÃºblicos Ex':lambda x:aggregate_strings(x,separator=', ',max_len=None)
    }
    agg_dict_ad_global_available={k:v for k,v in agg_dict_base.items() if k in df_daily_agg_copy.columns} 
    if not agg_dict_ad_global_available: log_func("Adv: No hay columnas para agregaciÃ³n global Ads."); return

    ad_global_metrics_raw=df_daily_agg_copy.groupby(group_cols_ad,as_index=False,observed=False).agg(agg_dict_ad_global_available) 

    if all(c_col in ad_global_metrics_raw.columns for c_col in ['value','spend']): ad_global_metrics_raw['roas']=safe_division(ad_global_metrics_raw['value'],ad_global_metrics_raw['spend'])
    if all(c_col in ad_global_metrics_raw.columns for c_col in ['spend','purchases']): ad_global_metrics_raw['cpa']=safe_division(ad_global_metrics_raw['spend'],ad_global_metrics_raw['purchases'])
    if all(c_col in ad_global_metrics_raw.columns for c_col in ['clicks','impr']): ad_global_metrics_raw['ctr']=safe_division_pct(ad_global_metrics_raw['clicks'],ad_global_metrics_raw['impr'])
    if all(c_col in ad_global_metrics_raw.columns for c_col in ['clicks_out','impr']): ad_global_metrics_raw['ctr_out']=safe_division_pct(ad_global_metrics_raw['clicks_out'],ad_global_metrics_raw['impr'])
    if all(c_col in ad_global_metrics_raw.columns for c_col in ['spend','impr']): ad_global_metrics_raw['cpm']=safe_division(ad_global_metrics_raw['spend'],ad_global_metrics_raw['impr'])*1000
    if all(c_col in ad_global_metrics_raw.columns for c_col in ['impr','reach']): ad_global_metrics_raw['frequency']=safe_division(ad_global_metrics_raw['impr'],ad_global_metrics_raw['reach'])
    base_rv_col_g = 'rv3' if 'rv3' in ad_global_metrics_raw.columns and ad_global_metrics_raw['rv3'].sum() > 0 else 'impr'
    if base_rv_col_g in ad_global_metrics_raw.columns:
        base_sum_g = ad_global_metrics_raw[base_rv_col_g]
        if 'rv25' in ad_global_metrics_raw.columns: ad_global_metrics_raw['rv25_pct'] = safe_division_pct(ad_global_metrics_raw['rv25'], base_sum_g)
        if 'rv75' in ad_global_metrics_raw.columns: ad_global_metrics_raw['rv75_pct'] = safe_division_pct(ad_global_metrics_raw['rv75'], base_sum_g)
        if 'rv100' in ad_global_metrics_raw.columns: ad_global_metrics_raw['rv100_pct'] = safe_division_pct(ad_global_metrics_raw['rv100'], base_sum_g)

    log_func(f"AgregaciÃ³n global OK ({len(ad_global_metrics_raw)} filas).")

    ad_period_metrics_raw={}; periods_to_calc=[3,7] 
    for p_days in periods_to_calc:
        log_func(f"Calculando mÃ©tricas U{p_days}...");
        period_start_date=max(max_date_val-timedelta(days=p_days-1),min_data_date_val) 
        if period_start_date <= max_date_val: 
            df_daily_period=df_daily_agg_copy[(df_daily_agg_copy['date']>=period_start_date)&(df_daily_agg_copy['date']<=max_date_val)].copy();
        else: 
            df_daily_period = pd.DataFrame(columns=df_daily_agg_copy.columns)

        if df_daily_period.empty: ad_period_metrics_raw[p_days]=pd.DataFrame(columns=group_cols_ad + list(agg_dict_base.keys())) 
        else: 
            agg_dict_period={k:v for k,v in agg_dict_base.items() if k in df_daily_period.columns} 
            if not agg_dict_period: ad_period_metrics_raw[p_days]=pd.DataFrame(columns=group_cols_ad + list(agg_dict_base.keys())) 
            else: 
                 df_p=df_daily_period.groupby(group_cols_ad,as_index=False,observed=False).agg(agg_dict_period)
                 if all(c_col in df_p.columns for c_col in ['value','spend']): df_p['roas']=safe_division(df_p['value'],df_p['spend'])
                 if all(c_col in df_p.columns for c_col in ['spend','purchases']): df_p['cpa']=safe_division(df_p['spend'],df_p['purchases'])
                 if all(c_col in df_p.columns for c_col in ['clicks','impr']): df_p['ctr']=safe_division_pct(df_p['clicks'],df_p['impr'])
                 if all(c_col in df_p.columns for c_col in ['clicks_out','impr']): df_p['ctr_out']=safe_division_pct(df_p['clicks_out'],df_p['impr'])
                 if all(c_col in df_p.columns for c_col in ['spend','impr']): df_p['cpm']=safe_division(df_p['spend'],df_p['impr'])*1000
                 if all(c_col in df_p.columns for c_col in ['impr','reach']): df_p['frequency']=safe_division(df_p['impr'],df_p['reach'])
                 base_rv_col_p = 'rv3' if 'rv3' in df_p.columns and df_p['rv3'].sum() > 0 else 'impr'
                 if base_rv_col_p in df_p.columns:
                     base_sum_p = df_p[base_rv_col_p]
                     if 'rv25' in df_p.columns: df_p['rv25_pct'] = safe_division_pct(df_p['rv25'], base_sum_p)
                     if 'rv75' in df_p.columns: df_p['rv75_pct'] = safe_division_pct(df_p['rv75'], base_sum_p)
                     if 'rv100' in df_p.columns: df_p['rv100_pct'] = safe_division_pct(df_p['rv100'], base_sum_p)
                 ad_period_metrics_raw[p_days]=df_p 
        log_func(f"AgregaciÃ³n U{p_days} OK ({len(ad_period_metrics_raw[p_days]) if p_days in ad_period_metrics_raw else 0} filas).")

    log_func("Fusionando mÃ©tricas..."); ad_metrics=ad_global_metrics_raw.copy() 
    ad_metrics.columns=[f"{c_col}_global" if c_col not in group_cols_ad else c_col for c_col in ad_metrics.columns] 
    for p_days in periods_to_calc: 
        if p_days in ad_period_metrics_raw:
            df_p=ad_period_metrics_raw[p_days];
            if not df_p.empty:
                 merge_cols=[c_col for c_col in group_cols_ad if c_col in ad_metrics.columns and c_col in df_p.columns] 
                 if merge_cols:
                     for col in merge_cols:
                         ad_metrics[col] = ad_metrics[col].astype(str)
                         df_p[col] = df_p[col].astype(str)
                     df_p_renamed=df_p.rename(columns={c_col:f"{c_col}_u{p_days}" for c_col in df_p.columns if c_col not in group_cols_ad}) 
                     ad_metrics=pd.merge(ad_metrics,df_p_renamed,on=merge_cols,how='left') 
                 else: log_func(f"WARN: No se encontraron columnas comunes para fusionar mÃ©tricas U{p_days}.")
            else: 
                 log_func(f"WARN: Datos U{p_days} vacÃ­os. Rellenando columnas con NaN.")
                 for c_base in agg_dict_base.keys(): 
                     c_p_name=f"{c_base}_u{p_days}";
                     if c_p_name not in ad_metrics.columns: ad_metrics[c_p_name]=np.nan 
        else: 
            log_func(f"WARN: No hay datos para U{p_days}. Rellenando columnas con NaN.")
            for c_base in agg_dict_base.keys():
                 c_p_name=f"{c_base}_u{p_days}";
                 if c_p_name not in ad_metrics.columns: ad_metrics[c_p_name]=np.nan
    log_func(f"FusiÃ³n periodos OK.")

    log_func("Fusionando DÃ­as Activos..."); 
    if not active_days_total_ad_df.empty and 'DÃ­as_Activo_Total' in active_days_total_ad_df.columns:
        merge_cols=[c_col for c_col in group_cols_ad if c_col in active_days_total_ad_df.columns] 
        if merge_cols:
             for col in merge_cols:
                 ad_metrics[col] = ad_metrics[col].astype(str)
                 active_days_total_ad_df[col] = active_days_total_ad_df[col].astype(str)
             ad_metrics=pd.merge(ad_metrics,active_days_total_ad_df[merge_cols+['DÃ­as_Activo_Total']],on=merge_cols,how='left');
        else: log_func("Adv: No cols comunes para fusionar DÃ­as Activos.")
    if 'DÃ­as_Activo_Total' not in ad_metrics.columns: ad_metrics['DÃ­as_Activo_Total'] = 0 
    ad_metrics['DÃ­as_Activo_Total']=ad_metrics['DÃ­as_Activo_Total'].fillna(0).astype(int); 
    log_func("FusiÃ³n DÃ­as Activos OK.")

    log_func("Fusionando Estado Ãšltimo DÃ­a..."); 
    if last_day_status_lookup is not None and not last_day_status_lookup.empty:
         s_cols_prio=['ad_delivery_status','adset_delivery_status','campaign_delivery_status', 'entrega']; 
         s_col_use=next((c_col for c_col in s_cols_prio if c_col in last_day_status_lookup.columns),None) 
         if s_col_use:
              merge_cols_s=[c_col for c_col in group_cols_ad if c_col in last_day_status_lookup.columns] 
              if merge_cols_s:
                 for col in merge_cols_s:
                      ad_metrics[col] = ad_metrics[col].astype(str)
                      last_day_status_lookup[col] = last_day_status_lookup[col].astype(str)
                 last_day_df=last_day_status_lookup[merge_cols_s+[s_col_use]].rename(columns={s_col_use:'Estado_Raw'}).drop_duplicates(subset=merge_cols_s,keep='last') 
                 ad_metrics=pd.merge(ad_metrics,last_day_df,on=merge_cols_s,how='left') 
                 map_last={'active':'Activo âœ…','inactive':'Inactivo âŒ','not_delivering':'Sin Entrega âš ï¸','rejected':'Rechazado â›”','pending_review':'Pendiente â³', 'archived':'Archivado ðŸ“¦', 'completed': 'CompletadoðŸ', 'limited':'LimitadoðŸ¤', 'not approved':'No Aprob.ðŸš«'} 
                 ad_metrics['Estado_Ult_Dia']=ad_metrics['Estado_Raw'].fillna('Desc.').astype(str).str.lower().str.replace('_',' ').str.strip().map(map_last).fillna('Otro ?') 
                 log_func(f"FusiÃ³n Estado OK (usando '{s_col_use}').")
              else: log_func("Adv: No cols comunes para fusionar estado.")
         else: log_func("Adv: No se encontrÃ³ columna de estado adecuada en lookup.")
    if 'Estado_Ult_Dia' not in ad_metrics.columns: ad_metrics['Estado_Ult_Dia']='Desc. ?' 

    log_func("Calculando U7 Estabilidad CPM..."); ad_metrics['cpm_stability_u7']=np.nan 
    u7_start_val=max(max_date_val-timedelta(days=6),min_data_date_val); 
    if u7_start_val <= max_date_val: 
        df_u7_stab=df_daily_agg_copy[(df_daily_agg_copy['date']>=u7_start_val)&(df_daily_agg_copy['date']<=max_date_val)&(df_daily_agg_copy['cpm'].notna())&(np.isfinite(df_daily_agg_copy['cpm']))].copy() 
        if not df_u7_stab.empty and 'cpm' in df_u7_stab.columns:
            try:
                grouped=df_u7_stab.groupby(group_cols_ad,observed=False)['cpm']; 
                stab_res=grouped.apply(lambda s_series:_calculate_stability_pct(s_series) if s_series.count()>=2 else np.nan).rename('cpm_stability_u7_calc') 
                merge_cols_st=[c_col for c_col in group_cols_ad if c_col in ad_metrics.columns and c_col in stab_res.index.names] 
                if merge_cols_st and not stab_res.empty:
                    ad_metrics=pd.merge(ad_metrics,stab_res.reset_index(),on=merge_cols_st,how='left') 
                    ad_metrics['cpm_stability_u7']=ad_metrics['cpm_stability_u7_calc'] 
                    if 'cpm_stability_u7_calc' in ad_metrics.columns: 
                        ad_metrics=ad_metrics.drop(columns=['cpm_stability_u7_calc'],errors='ignore')
                    processed=ad_metrics['cpm_stability_u7'].notna().sum(); log_func(f"Estabilidad CPM U7 OK ({processed} ads calculados).")
                else: log_func("Adv: No se pudo fusionar estabilidad CPM U7 (Â¿no hay grupos con >=2 dÃ­as o no hay columnas comunes?).")
            except Exception as e_stab: log_func(f"Error calculando estabilidad CPM U7: {e_stab}")
        else: log_func("Adv: No hay datos U7 vÃ¡lidos para calcular estabilidad CPM.")
    else: log_func("Adv: Rango U7 invÃ¡lido (start > end). No se calcula estabilidad CPM.")
    if 'cpm_stability_u7' not in ad_metrics.columns: ad_metrics['cpm_stability_u7']=np.nan 

    log_func("Filtrando Anuncios...", importante=True); spend_g='spend_global'; impr_g='impr_global'; dias='DÃ­as_Activo_Total'
    filtered_ads=ad_metrics.copy(); initial_ad_count=len(filtered_ads); cond=pd.Series(True,index=filtered_ads.index) 
    if spend_g in filtered_ads.columns: cond&=(pd.to_numeric(filtered_ads[spend_g],errors='coerce').fillna(0)>0) 
    else: log_func(f"Adv: Falta columna '{spend_g}' para filtrar Ads. No se filtrarÃ¡ por gasto.");
    if impr_g in filtered_ads.columns: cond&=(pd.to_numeric(filtered_ads[impr_g],errors='coerce').fillna(0)>0) 
    else: log_func(f"Adv: Falta columna '{impr_g}' para filtrar Ads. No se filtrarÃ¡ por impresiones.");
    if dias in filtered_ads.columns: cond&=(pd.to_numeric(filtered_ads[dias],errors='coerce').fillna(0)>0) 
    else: log_func(f"Adv: Falta columna '{dias}' para filtrar Ads. No se filtrarÃ¡ por dÃ­as activos.");

    filtered_ads=filtered_ads[cond].copy() 
    log_func(f"Ads iniciales: {initial_ad_count}. Cumplen filtros (Gasto>0, Impr>0, DÃ­as>0): {len(filtered_ads)}", importante=True)
    if filtered_ads.empty: log_func("\n** No se encontraron Anuncios que cumplan los filtros para analizar. **", importante=True); return

    log_func("\nGenerando tablas consolidadas de Ads...");
    log_func("  Preparando Tabla Rendimiento Consolidada...");
    sort_col_roas = 'roas_global' if 'roas_global' in filtered_ads.columns else None
    if sort_col_roas:
        df_ads_sorted_spend = filtered_ads.sort_values(sort_col_roas, ascending=False, na_position='last').copy()
    else:
         log_func("Adv: No se pudo ordenar por ROAS (columna ausente).")
         df_ads_sorted_spend = filtered_ads.copy()

    t1_headers=['CampaÃ±a','AdSet','Nombre ADs','PÃºblicos Incluidos','PÃºblicos Excluidos','dias','Estado','Alcance','ROAS','Compras','CVR (%)','AOV','NCPA','CPM','CTR','CTR Saliente','Var U7 CTR','Var U7 ROAS','Var U7 Freq','Var U7 CPM','Var U7 Compras']
    t1_data=[]
    for _,r_row in df_ads_sorted_spend.iterrows(): t1_data.append({
        'CampaÃ±a':_remove_commas(r_row.get('Campaign','-')),
        'AdSet':_remove_commas(r_row.get('AdSet','-')),
        'Nombre ADs':_remove_commas(r_row.get('Anuncio','-')),
        'PÃºblicos Incluidos':_clean_audience_string(r_row.get('PÃºblicos In_global','-')),
        'PÃºblicos Excluidos':_clean_audience_string(r_row.get('PÃºblicos Ex_global','-')),
        'dias':fmt_int(r_row.get('DÃ­as_Activo_Total', 0)),
        'Estado':r_row.get('Estado_Ult_Dia','-'),
        'Alcance':fmt_int(r_row.get('reach_global')),
        'ROAS':f"{fmt_float(r_row.get('roas_global'),2)}x",
        'Compras':fmt_int(r_row.get('purchases_global')),
        'CVR (%)':fmt_pct(safe_division_pct(r_row.get('purchases_global'), r_row.get('visits_global')),2),
        'AOV':f"{detected_currency}{fmt_float(safe_division(r_row.get('value_global'), r_row.get('purchases_global')),2)}",
        'NCPA':f"{detected_currency}{fmt_float(r_row.get('cpa_global'),2)}",
        'CPM':f"{detected_currency}{fmt_float(r_row.get('cpm_global'),2)}",
        'CTR':fmt_pct(r_row.get('ctr_global'),2),
        'CTR Saliente':fmt_pct(r_row.get('ctr_out_global'),2),
        'Var U7 CTR':variation(r_row.get('ctr_u7'),r_row.get('ctr_global')), 
        'Var U7 ROAS':variation(r_row.get('roas_u7'),r_row.get('roas_global')),
        'Var U7 Freq':variation(r_row.get('frequency_u7'),r_row.get('frequency_global')),
        'Var U7 CPM':variation(r_row.get('cpm_u7'),r_row.get('cpm_global')),
        'Var U7 Compras':variation(r_row.get('purchases_u7'),r_row.get('purchases_global'))
        })
    if t1_data: 
        df_t1=pd.DataFrame(t1_data)
        df_t1 = df_t1[[h for h in t1_headers if h in df_t1.columns]] 
        num_cols_t1=[h for h in df_t1.columns if h not in ['CampaÃ±a','AdSet','Nombre ADs','Estado','PÃºblicos Incluidos','PÃºblicos Excluidos']]
        _format_dataframe_to_markdown(
            df_t1,
            f"** Tabla Ads: Rendimiento y VariaciÃ³n (Orden: ROAS Desc) **",
            log_func,
            currency_cols=detected_currency,
            numeric_cols_for_alignment=num_cols_t1,
            max_col_width=None,
        )
        log_func("\n  **Detalle Tabla Ads: Rendimiento y VariaciÃ³n:**");
        log_func("  * **Columnas principales (Alcance, ROAS, etc.):** Muestran el valor *Global Acumulado* para cada Ad durante todo el perÃ­odo de datos analizado.")
        log_func("  * **Columnas 'Var UX ...':** Muestran la variaciÃ³n porcentual del rendimiento en los *Ãšltimos 7 DÃ­as* (U7) en comparaciÃ³n con el rendimiento *Global Acumulado* de ese mismo Ad. Una flecha ðŸ”º indica mejora, ðŸ”» indica empeoramiento respecto al global del Ad. Ayuda a identificar tendencias recientes.");
        log_func("  ---")
    else: log_func("  No hay datos para Tabla Rendimiento.")

    log_func("\n  Preparando Tabla Creatividad Consolidada...");
    roas_g='roas_global'; reach_g='reach_global'; dias_col='DÃ­as_Activo_Total' 
    sort_cols_roas=[c_col for c_col in [roas_g,reach_g,dias_col] if c_col in filtered_ads.columns]; 
    ascend_roas=[False, False, False] 

    df_ads_sorted_roas=filtered_ads.copy()
    if sort_cols_roas: 
         for scol,asc_val in zip(sort_cols_roas,ascend_roas):
              if pd.api.types.is_numeric_dtype(df_ads_sorted_roas[scol]):
                  fill_value = -np.inf if not asc_val else np.inf 
                  df_ads_sorted_roas[scol]=df_ads_sorted_roas[scol].fillna(fill_value)
         df_ads_sorted_roas=df_ads_sorted_roas.sort_values(by=sort_cols_roas,ascending=ascend_roas)
    else: 
         log_func("Adv: No se pudo ordenar por ROAS/Reach/DÃ­as (columnas ausentes).")

    t2_headers=['CampaÃ±a','AdSet','Nombre Ads','PÃºblicos Incluidos','PÃºblicos Excluidos','dias','Estado','CTR Glob (%)','Tiempo RV (s)','% RV 25','% RV 75','% RV 100','CPM Stab U7 (%)']
    t2_data=[]
    for _,r_row in df_ads_sorted_roas.iterrows(): t2_data.append({
        'CampaÃ±a':_remove_commas(r_row.get('Campaign','-')),
        'AdSet':_remove_commas(r_row.get('AdSet','-')),
        'Nombre Ads':_remove_commas(r_row.get('Anuncio','-')),
        'PÃºblicos Incluidos':str(r_row.get('PÃºblicos In_global','-')),
        'PÃºblicos Excluidos':str(r_row.get('PÃºblicos Ex_global','-')),
        'dias':fmt_int(r_row.get('DÃ­as_Activo_Total', 0)),
        'Estado':r_row.get('Estado_Ult_Dia','-'),
        'CTR Glob (%)':fmt_pct(r_row.get('ctr_global'),2),
        'Tiempo RV (s)':f"{fmt_float(r_row.get('rtime_global'),1)}s",
        '% RV 25':fmt_pct(r_row.get('rv25_pct_global'),1),
        '% RV 75':fmt_pct(r_row.get('rv75_pct_global'),1),
        '% RV 100':fmt_pct(r_row.get('rv100_pct_global'),1),
        'CPM Stab U7 (%)':fmt_stability(r_row.get('cpm_stability_u7'))
        })
    if t2_data: 
        df_t2=pd.DataFrame(t2_data)
        df_t2 = df_t2[[h for h in t2_headers if h in df_t2.columns]] 
        num_cols_t2=[h for h in df_t2.columns if h not in ['CampaÃ±a','AdSet','Nombre Ads','Estado','PÃºblicos Incluidos','PÃºblicos Excluidos']] 
        stab_cols_t2=[h for h in df_t2.columns if 'Stab' in h] 
        _format_dataframe_to_markdown(
            df_t2,
            f"** Tabla Ads: Creatividad y Audiencia (Orden: ROAS Desc > Alcance Desc > DÃ­as Act Desc) **",
            log_func,
            currency_cols=detected_currency,
            stability_cols=stab_cols_t2,
            numeric_cols_for_alignment=num_cols_t2,
            max_col_width=None,
        )
        log_func("\n  **Detalle Tabla Ads: Creatividad y Audiencia:**");
        log_func("  * **CTR Glob (%):** Porcentaje global de clics en el enlace sobre impresiones para el Ad.")
        log_func("  * **Tiempo RV (s):** Tiempo promedio global de reproducciÃ³n del video (si aplica).")
        log_func("  * **% RV X%:** Porcentaje global de reproducciones de video que alcanzaron X% de su duraciÃ³n. Base: Impresiones (o Repr. 3s si > 0).")
        log_func("  * **CPM Stab U7 (%):** Estabilidad del Costo Por Mil Impresiones en los Ãºltimos 7 dÃ­as para este Ad.")
        log_func("  * **PÃºblicos:** PÃºblicos personalizados usados por el Ad (agregados si varÃ­an).");
        log_func("  ---")
    else: log_func("  No hay datos para Tabla Creatividad.")
    log_func("\n--- Fin AnÃ¡lisis Consolidado de Ads ---")


def _generar_tabla_top_ads_historico(df_daily_agg, active_days_total_ad_df, log_func, detected_currency, top_n=20):
    """List historically best performing ads by spend and ROAS."""

    log_func("\n\n============================================================");log_func(f"===== 6. Top {top_n} Ads HistÃ³rico (Orden: ROAS Desc) =====");log_func("============================================================")
    group_cols_ad=['Campaign','AdSet','Anuncio'] 
    essential_cols = group_cols_ad + ['spend','impr'] 
    if df_daily_agg is None or df_daily_agg.empty or not all(c_col in df_daily_agg.columns for c_col in essential_cols):
        log_func("   Faltan columnas esenciales (Campaign, AdSet, Anuncio, spend, impr) para Top Ads."); return

    df_daily_agg_copy = df_daily_agg.copy() 
    for col in group_cols_ad:
        if col in df_daily_agg_copy.columns:
            df_daily_agg_copy[col] = df_daily_agg_copy[col].astype(str)

    agg_dict={
        'spend':'sum','value':'sum','purchases':'sum','clicks':'sum','visits':'sum',
        'impr':'sum','reach':'sum','rtime':'mean','rv3':'sum',
        'rv25':'sum','rv75':'sum','rv100':'sum','thruplays':'sum','puja':'mean',
        'url_final':lambda x: aggregate_strings(x, separator=' | ', max_len=None),
        'PÃºblicos In': lambda x: aggregate_strings(x, separator=', ', max_len=None),
        'PÃºblicos Ex': lambda x: aggregate_strings(x, separator=', ', max_len=None)
    }
    agg_dict_available={k:v for k,v in agg_dict.items() if k in df_daily_agg_copy.columns} 
    if not agg_dict_available or 'spend' not in agg_dict_available or 'impr' not in agg_dict_available: 
        log_func("   No hay mÃ©tricas suficientes (falta spend o impr) para agregar para Top Ads."); return

    ads_global=df_daily_agg_copy.groupby(group_cols_ad,observed=False,as_index=False).agg(agg_dict_available) 

    if all(c_col in ads_global for c_col in ['value','spend']): ads_global['roas']=safe_division(ads_global['value'],ads_global['spend'])
    if all(c_col in ads_global for c_col in ['clicks','impr']): ads_global['ctr']=safe_division_pct(ads_global['clicks'],ads_global['impr'])
    if all(c_col in ads_global for c_col in ['impr','reach']):
        ads_global['frequency']=safe_division(ads_global['impr'],ads_global['reach'])
    base_rv_col = 'rv3' if 'rv3' in ads_global.columns and ads_global['rv3'].sum() > 0 else 'impr'
    if base_rv_col in ads_global.columns:
        base_sum = ads_global[base_rv_col]
        if 'rv25' in ads_global.columns:
            ads_global['rv25_pct'] = safe_division_pct(ads_global['rv25'], base_sum)
        if 'rv75' in ads_global.columns:
            ads_global['rv75_pct'] = safe_division_pct(ads_global['rv75'], base_sum)
        if 'rv100' in ads_global.columns:
            ads_global['rv100_pct'] = safe_division_pct(ads_global['rv100'], base_sum)
    if active_days_total_ad_df is not None and not active_days_total_ad_df.empty and 'DÃ­as_Activo_Total' in active_days_total_ad_df.columns:
        merge_cols=[c_col for c_col in group_cols_ad if c_col in active_days_total_ad_df.columns] 
        if merge_cols:
             for col in merge_cols:
                 ads_global[col] = ads_global[col].astype(str)
                 active_days_total_ad_df[col] = active_days_total_ad_df[col].astype(str)
             ads_global=pd.merge(ads_global,active_days_total_ad_df[merge_cols+['DÃ­as_Activo_Total']],on=merge_cols,how='left');
             ads_global['DÃ­as_Activo_Total']=ads_global['DÃ­as_Activo_Total'].fillna(0).astype(int) 
    if 'DÃ­as_Activo_Total' not in ads_global: ads_global['DÃ­as_Activo_Total']=0 

    ads_global=ads_global[(ads_global['impr'].fillna(0)>0)&(ads_global['spend'].fillna(0)>0)].copy() 
    if ads_global.empty: log_func("   No hay Ads con impresiones y gasto positivos."); return

    sort_cols_top=[]; ascend_top=[]
    if 'roas' in ads_global: sort_cols_top.append('roas'); ascend_top.append(False)

    df_top=ads_global.copy()
    if sort_cols_top: 
         for scol,asc_val in zip(sort_cols_top,ascend_top):
              if pd.api.types.is_numeric_dtype(df_top[scol]):
                  fill_value = -np.inf if not asc_val else np.inf
                  df_top[scol]=df_top[scol].fillna(fill_value)
         df_top=df_top.sort_values(by=sort_cols_top,ascending=ascend_top).head(top_n) 
    else: 
        log_func("   No se pudo ordenar Top Ads (faltan columnas spend/roas). Mostrando los primeros {top_n}.")
        df_top=df_top.head(top_n)

    table_headers=[
        'CampaÃ±a','AdSet','Anuncio','PÃºblicos Incluidos','PÃºblicos Excluidos','URL FINAL','Puja','ThruPlays',
        'Reproducciones 25%','Reproducciones 75%','Reproducciones 100%',
        'Tiempo RV (s)','DÃ­as Act','Gasto','ROAS','Compras','CVR (%)','AOV','NCPA','CTR (%)','Frecuencia'
    ]

    table_data=[]
    for _,row_val in df_top.iterrows():
        rv_cols_present = any(row_val.get(c,0)>0 for c in ['rv25','rv75','rv100']) or row_val.get('rtime',0)>0
        table_data.append({
        'CampaÃ±a':_remove_commas(row_val.get('Campaign','-')),
        'AdSet':_remove_commas(row_val.get('AdSet','-')),
        'Anuncio':_remove_commas(row_val.get('Anuncio','-')),
        'PÃºblicos Incluidos': _clean_audience_string(row_val.get('PÃºblicos In', '-')),
        'PÃºblicos Excluidos': _clean_audience_string(row_val.get('PÃºblicos Ex', '-')),
        'URL FINAL':row_val.get('url_final','-'),
        'Puja':f"{detected_currency}{fmt_float(row_val.get('puja'),2)}" if pd.notna(row_val.get('puja')) else '-',
        'ThruPlays':fmt_int(row_val.get('thruplays')),
        'Reproducciones 25%':fmt_int(row_val.get('rv25')) if rv_cols_present else '-',
        'Reproducciones 75%':fmt_int(row_val.get('rv75')) if rv_cols_present else '-',
        'Reproducciones 100%':fmt_int(row_val.get('rv100')) if rv_cols_present else '-',
        'Tiempo RV (s)':f"{fmt_float(row_val.get('rtime'),1)}s" if rv_cols_present else '-',
        'DÃ­as Act':fmt_int(row_val.get('DÃ­as_Activo_Total', 0)),
        'Gasto':f"{detected_currency}{fmt_float(row_val.get('spend'),0)}",
        'ROAS':f"{fmt_float(row_val.get('roas'),2)}x",
        'Compras':fmt_int(row_val.get('purchases')),
        'CVR (%)':fmt_pct(safe_division_pct(row_val.get('purchases'), row_val.get('visits')),2),
        'AOV':f"{detected_currency}{fmt_float(safe_division(row_val.get('value'), row_val.get('purchases')),2)}",
        'NCPA':f"{detected_currency}{fmt_float(safe_division(row_val.get('spend'), row_val.get('purchases')),2)}",
        'CTR (%)':fmt_pct(row_val.get('ctr'),2),
        'Frecuencia':fmt_float(row_val.get('frequency'),2),
        })
    if table_data: 
        df_display=pd.DataFrame(table_data)
        df_display = df_display[[h for h in table_headers if h in df_display.columns]] 
        num_cols=[h for h in df_display.columns if h not in ['CampaÃ±a','AdSet','Anuncio','URL FINAL','PÃºblicos Incluidos','PÃºblicos Excluidos']]
        _format_dataframe_to_markdown(df_display,f"** Top {top_n} Ads por Gasto > ROAS (Global Acumulado) **",log_func,currency_cols=detected_currency, stability_cols=[], numeric_cols_for_alignment=num_cols)
    else: log_func(f"   No hay datos para mostrar en Top {top_n} Ads.");
    log_func("\n  **Detalle Top Ads HistÃ³rico:** Muestra los anuncios con mejor rendimiento histÃ³rico, ordenados por ROAS de mayor a menor. Todas las mÃ©tricas son acumuladas globales.");
    log_func("  ---")

def _generar_tabla_bitacora_top_ads(df_daily_agg, bitacora_periods_list, active_days_total_ad_df, log_func, detected_currency, top_n=20):
    """Genera tablas por semana con los Top Ads ordenados por ROAS e impresiones."""
    group_cols = ['Campaign', 'AdSet', 'Anuncio']
    _generar_tabla_bitacora_top_entities(
        df_daily_agg,
        bitacora_periods_list,
        active_days_total_ad_df,
        log_func,
        detected_currency,
        group_cols,
        'Ads',
        METRIC_LABELS_ADS,
        ranking_method='ads',
        top_n=top_n,
    )

    log_func("\n  **Detalle Top Ads BitÃ¡cora:**")
    log_func("  * Tabla semanal con los anuncios con mayor ROAS y mayor nÃºmero de impresiones.")
    log_func("  * Las columnas estÃ¡n separadas por ';' para facilitar la importaciÃ³n en hojas de cÃ¡lculo.")
    log_func("  ---")


def _generar_tabla_bitacora_top_entities(
    df_daily_agg,
    bitacora_periods_list,
    active_days_df,
    log_func,
    detected_currency,
    group_cols,
    entity_label,
    metric_labels,
    ranking_method='reach',
    top_n=20,
    max_col_width=None,
):
    """Generic helper to build Top tables for Ads, AdSets or Campaigns."""
    if df_daily_agg is None or df_daily_agg.empty or 'date' not in df_daily_agg.columns:
        log_func(f"\nNo hay datos diarios para Top {entity_label} BitÃ¡cora.")
        return
    if not bitacora_periods_list:
        log_func(f"\nNo se proporcionaron perÃ­odos para Top {entity_label} BitÃ¡cora.")
        return

    periods_to_use = bitacora_periods_list[:3]
    period_labels = [p[2] for p in periods_to_use]

    agg_dict = {
        'spend': 'sum', 'value': 'sum', 'purchases': 'sum', 'clicks': 'sum',
        'clicks_out': 'sum', 'impr': 'sum', 'reach': 'sum', 'visits': 'sum',
        'rv3': 'sum', 'rv25': 'sum', 'rv75': 'sum', 'rv100': 'sum', 'rtime': 'mean',
        'puja': 'mean', 'interacciones': 'sum', 'comentarios': 'sum',
        'url_final': lambda x: aggregate_strings(x, separator=' | ', max_len=None),
        'PÃºblicos In': lambda x: aggregate_strings(x, separator=', ', max_len=None),
        'PÃºblicos Ex': lambda x: aggregate_strings(x, separator=', ', max_len=None),
    }

    period_metrics = {}
    for start_dt, end_dt, label in periods_to_use:
        df_p = df_daily_agg[
            (df_daily_agg['date'].dt.date >= start_dt.date()) &
            (df_daily_agg['date'].dt.date <= end_dt.date())
        ].copy()
        if df_p.empty:
            period_metrics[label] = pd.DataFrame(columns=group_cols)
            continue
        df_g = df_p.groupby(group_cols, as_index=False, observed=False).agg({k: v for k, v in agg_dict.items() if k in df_p.columns})
        # Calculate active days within the period for each entity
        active_days = (
            df_p.groupby(group_cols, as_index=False)['date']
            .nunique()
            .rename(columns={'date': 'active_days_period'})
        )
        if not active_days.empty:
            df_g = pd.merge(df_g, active_days, on=group_cols, how='left')
        if not df_g.empty:
            s = df_g.get('spend', pd.Series(np.nan, index=df_g.index))
            v = df_g.get('value', pd.Series(np.nan, index=df_g.index))
            p = df_g.get('purchases', pd.Series(np.nan, index=df_g.index))
            c = df_g.get('clicks', pd.Series(np.nan, index=df_g.index))
            co = df_g.get('clicks_out', pd.Series(np.nan, index=df_g.index))
            i = df_g.get('impr', pd.Series(np.nan, index=df_g.index))
            r = df_g.get('reach', pd.Series(np.nan, index=df_g.index))
            vi = df_g.get('visits', pd.Series(np.nan, index=df_g.index))
            rv3 = df_g.get('rv3', pd.Series(np.nan, index=df_g.index))
            rv25 = df_g.get('rv25', pd.Series(np.nan, index=df_g.index))
            rv75 = df_g.get('rv75', pd.Series(np.nan, index=df_g.index))
            rv100 = df_g.get('rv100', pd.Series(np.nan, index=df_g.index))
            df_g['roas'] = safe_division(v, s)
            df_g['cpa'] = safe_division(s, p)
            df_g['ctr'] = safe_division_pct(c, i)
            df_g['ctr_out'] = safe_division_pct(co, i)
            df_g['cpm'] = safe_division(s, i) * 1000
            df_g['frequency'] = safe_division(i, r)
            df_g['lpv_rate'] = safe_division_pct(vi, c)
            df_g['purchase_rate'] = safe_division_pct(p, vi)
            base_rv = np.where(pd.Series(rv3 > 0).fillna(False), rv3, i)
            df_g['rv25_pct'] = safe_division_pct(rv25, base_rv)
            df_g['rv75_pct'] = safe_division_pct(rv75, base_rv)
            df_g['rv100_pct'] = safe_division_pct(rv100, base_rv)
            df_g['ticket_promedio'] = safe_division(v, p)
        period_metrics[label] = df_g

    if period_metrics[period_labels[0]].empty:
        log_func(f"\nNo hay datos para el primer perÃ­odo. Top {entity_label} BitÃ¡cora omitido.")
        return

    any_table = False
    display_map = {
        'Campaign': 'CampaÃ±a',
        'AdSet': 'AdSet',
        'Anuncio': 'Anuncio',
    }

    for label in period_labels:
        df_metrics = period_metrics.get(label)
        if df_metrics is None or df_metrics.empty:
            continue

        ranking_df = df_metrics.copy()
        if active_days_df is not None and not active_days_df.empty:
            merge_cols = [c for c in group_cols if c in active_days_df.columns]
            if merge_cols:
                dedup_active = active_days_df.drop_duplicates(subset=merge_cols)
                ranking_df = pd.merge(
                    ranking_df,
                    dedup_active[merge_cols + ['DÃ­as_Activo_Total']],
                    on=merge_cols,
                    how='left',
                )
        if 'DÃ­as_Activo_Total' in ranking_df.columns:
            ranking_df['DÃ­as_Activo_Total'] = ranking_df['DÃ­as_Activo_Total'].fillna(0).astype(int)
        else:
            ranking_df['DÃ­as_Activo_Total'] = 0

        ranking_df['roas'] = pd.to_numeric(ranking_df.get('roas'), errors='coerce').fillna(0)
        ranking_df['impr'] = pd.to_numeric(ranking_df.get('impr'), errors='coerce').fillna(0)
        ranking_df = ranking_df.sort_values(['roas', 'impr'], ascending=[False, False]).head(top_n)

        table_rows = []
        for _, key_row in ranking_df.iterrows():
            dias_act = int(key_row.get('DÃ­as_Activo_Total', 0))
            if 'active_days_period' in key_row:
                dias_act = int(key_row.get('active_days_period', dias_act))
            base_metrics = {
                'ROAS': f"{fmt_float(key_row.get('roas'),2)}x",
                'InversiÃ³n': f"{detected_currency}{fmt_float(key_row.get('spend'),2)}",
                'Compras': fmt_int(key_row.get('purchases')),
                'Ventas': f"{detected_currency}{fmt_float(key_row.get('value'),2)}",
                'NCPA': f"{detected_currency}{fmt_float(safe_division(key_row.get('spend'), key_row.get('purchases')),2)}",
                'CVR': fmt_pct(safe_division_pct(key_row.get('purchases'), key_row.get('visits')),2),
                'AOV': f"{detected_currency}{fmt_float(safe_division(key_row.get('value'), key_row.get('purchases')),2)}",
                'Alcance': fmt_int(key_row.get('reach')),
                'Impresiones': fmt_int(key_row.get('impr')),
                'CTR': fmt_pct(key_row.get('ctr'),2),
                'Frecuencia': fmt_float(key_row.get('frequency'),2),
                'RV25%': fmt_pct(key_row.get('rv25_pct'),2),
                'RV75%': fmt_pct(key_row.get('rv75_pct'),2),
                'RV100%': fmt_pct(key_row.get('rv100_pct'),2),
                'Tiempo RV (s)': f"{fmt_float(key_row.get('rtime'),1)}s",
                'Presupuesto CampaÃ±a': f"{detected_currency}{fmt_float(key_row.get('campaign_budget'),2)}" if key_row.get('campaign_budget') is not None else '-',
                'Presupuesto Adset': f"{detected_currency}{fmt_float(key_row.get('adset_budget'),2)}" if key_row.get('adset_budget') is not None else '-',
                'Objetivo': key_row.get('objective','-'),
                'Tipo Compra': key_row.get('purchase_type','-'),
                'Estado Entrega': key_row.get('delivery_general_status','-'),
            }
            metrics = {k: base_metrics.get(k, '-') for k in metric_labels}

            row = {
                display_map.get(col, col): _remove_commas(key_row.get(col, '-'))
                for col in group_cols
            }
            row['DÃ­as Act'] = dias_act
            if 'PÃºblicos In' in key_row:
                row['PÃºblicos Incluidos'] = _clean_audience_string(key_row.get('PÃºblicos In', '-'))
            if 'PÃºblicos Ex' in key_row:
                row['PÃºblicos Excluidos'] = _clean_audience_string(key_row.get('PÃºblicos Ex', '-'))
            row.update(metrics)
            table_rows.append(row)

        if table_rows:
            df_display = pd.DataFrame(table_rows)
            base_cols = [display_map.get(c, c) for c in group_cols] + ['DÃ­as Act']
            if 'PÃºblicos Incluidos' in df_display.columns:
                base_cols += ['PÃºblicos Incluidos', 'PÃºblicos Excluidos']
            column_order = base_cols + metric_labels
            df_display = df_display[[c for c in column_order if c in df_display.columns]]
            df_display = df_display.drop_duplicates()
            exclude = ['PÃºblicos Incluidos', 'PÃºblicos Excluidos'] + base_cols
            num_cols = [c for c in df_display.columns if c not in exclude]
            _format_dataframe_to_markdown(
                df_display,
                f"Top {top_n} {entity_label} BitÃ¡cora - {label}",
                log_func,
                numeric_cols_for_alignment=num_cols,
                max_col_width=max_col_width,
            )
            any_table = True

    if not any_table:
        log_func(f"\nNo hay datos para Top {entity_label} BitÃ¡cora.")



def _generar_tabla_bitacora_top_adsets(df_daily_agg, bitacora_periods_list, active_days_total_adset_df, log_func, detected_currency, top_n=20):
    """Genera tablas por semana con los Top AdSets ordenados por ROAS."""
    group_cols = ['Campaign', 'AdSet']
    _generar_tabla_bitacora_top_entities(
        df_daily_agg,
        bitacora_periods_list,
        active_days_total_adset_df,
        log_func,
        detected_currency,
        group_cols,
        'AdSets',
        METRIC_LABELS_BASE,
        ranking_method='ads',
        top_n=top_n,
        max_col_width=None,
    )

    log_func("\n  **Detalle Top AdSets BitÃ¡cora:**")
    log_func("  * Tabla semanal ordenada por ROAS de cada conjunto de anuncios.")
    log_func("  * Al exportar, las columnas se separan con ';' para su lectura en planillas.")
    log_func("  ---")


def _generar_tabla_bitacora_top_campaigns(df_daily_agg, bitacora_periods_list, active_days_total_campaign_df, log_func, detected_currency, top_n=10):
    """Genera tablas por semana con las Top CampaÃ±as ordenadas por ROAS."""
    group_cols = ['Campaign']
    _generar_tabla_bitacora_top_entities(
        df_daily_agg,
        bitacora_periods_list,
        active_days_total_campaign_df,
        log_func,
        detected_currency,
        group_cols,
        'CampaÃ±as',
        METRIC_LABELS_BASE,
        ranking_method='ads',
        top_n=top_n,
    )

    log_func("\n  **Detalle Top CampaÃ±as BitÃ¡cora:**")
    log_func("  * Ranking semanal de campaÃ±as ordenadas por ROAS.")
    log_func("  * Las columnas usan ';' como separador para su importaciÃ³n en hojas de cÃ¡lculo.")
    log_func("  ---")


def _generar_tabla_performance_publico(df_daily_agg, log_func, detected_currency, top_n=5):
    """Construye tabla con mÃ©tricas de rendimiento por pÃºblico."""

    log_func("\n\n============================================================")
    log_func(f"===== Performance PÃºblico (Top {top_n}) =====")
    log_func("============================================================")

    if df_daily_agg is None or df_daily_agg.empty or 'PÃºblicos In' not in df_daily_agg.columns:
        log_func("No hay datos de pÃºblicos para analizar.")
        return

    df_aud = df_daily_agg.copy()
    df_aud['publico'] = df_aud['PÃºblicos In'].apply(_clean_audience_string)
    df_aud['publico'] = df_aud['publico'].replace({'': '(Sin PÃºblico)', '-': '(Sin PÃºblico)'})

    agg_cols = {col: 'sum' for col in ['spend', 'purchases', 'value', 'impr', 'clicks', 'reach'] if col in df_aud.columns}
    if not agg_cols:
        log_func("No hay columnas mÃ©tricas para pÃºblicos.")
        return

    df_group = df_aud.groupby('publico', as_index=False).agg(agg_cols)

    if 'value' in df_group.columns and 'spend' in df_group.columns:
        df_group['roas'] = safe_division(df_group['value'], df_group['spend'])
    if 'spend' in df_group.columns and 'impr' in df_group.columns:
        df_group['cpm'] = safe_division(df_group['spend'], df_group['impr']) * 1000
    if 'clicks' in df_group.columns and 'impr' in df_group.columns:
        df_group['ctr'] = safe_division_pct(df_group['clicks'], df_group['impr'])
    if 'spend' in df_group.columns and 'purchases' in df_group.columns:
        df_group['cpa'] = safe_division(df_group['spend'], df_group['purchases'])

    df_group = df_group.sort_values('spend', ascending=False).head(top_n)

    rename_map = {
        'publico': 'PÃºblico',
        'spend': 'Spend',
        'purchases': 'Compras',
        'roas': 'ROAS',
        'cpm': 'CPM',
        'ctr': 'CTR',
        'cpa': 'CPA',
        'reach': 'Alcance',
    }
    df_disp = df_group.rename(columns=rename_map)
    col_order = [c for c in ['PÃºblico','Spend','Compras','ROAS','CPM','CTR','CPA','Alcance'] if c in df_disp.columns]
    df_disp = df_disp[col_order]

    num_cols = [c for c in df_disp.columns if c != 'PÃºblico']
    pct_cols = {'CTR': 2}
    float_cols = {'ROAS': 2, 'CPM': 2}
    currency_cols = {'Spend': detected_currency, 'CPA': detected_currency}

    _format_dataframe_to_markdown(
        df_disp,
        f"TABLA: PERFORMANCE_PUBLICO",
        log_func,
        float_cols_fmt=float_cols,
        pct_cols_fmt=pct_cols,
        currency_cols=currency_cols,
        int_cols=[c for c in df_disp.columns if c in ['Compras','Alcance']],
        numeric_cols_for_alignment=num_cols,
    )


def _generar_tabla_tendencia_ratios(df_daily_total, bitacora_periods_list, log_func, period_type="Weeks"):
    """Genera tabla de tendencia de ratios por periodo."""

    label_map = {'Weeks': 'Semana', 'Months': 'Mes', 'Biweekly': 'Quincena'}
    header_label = label_map.get(period_type, 'Periodo')

    title_map = {'Weeks': 'Semanal', 'Months': 'Mensual', 'Biweekly': 'Quincenal'}
    log_func("\n\n============================================================")
    log_func(f"===== Tendencia Ratios ({title_map.get(period_type, period_type)}) =====")
    log_func("============================================================")

    if df_daily_total is None or df_daily_total.empty or 'date' not in df_daily_total.columns:
        log_func("No hay datos para calcular tendencias.")
        return

    metric_cols = ['clicks', 'impr', 'visits', 'addcart', 'checkout', 'purchases']
    if not any(col in df_daily_total.columns for col in metric_cols):
        log_func("No hay columnas suficientes para calcular ratios.")
        return

    rows = []
    for start_dt, end_dt, label in bitacora_periods_list:
        df_p = df_daily_total[
            (df_daily_total['date'].dt.date >= start_dt.date()) &
            (df_daily_total['date'].dt.date <= end_dt.date())
        ]
        clicks = df_p.get('clicks', pd.Series(dtype=float)).sum()
        impr = df_p.get('impr', pd.Series(dtype=float)).sum()
        visits = df_p.get('visits', pd.Series(dtype=float)).sum()
        addcart = df_p.get('addcart', pd.Series(dtype=float)).sum()
        checkout = df_p.get('checkout', pd.Series(dtype=float)).sum()
        purchases = df_p.get('purchases', pd.Series(dtype=float)).sum()

        ctr = safe_division_pct(clicks, impr)
        cvr_lp_cart = safe_division_pct(addcart, visits)
        cvr_cart_checkout = safe_division_pct(checkout, addcart)
        cvr_checkout_purchase = safe_division_pct(purchases, checkout)

        rows.append({
            header_label: label,
            'CTR': ctr,
            'CVR LPâ†’Cart': cvr_lp_cart,
            'CVR Cartâ†’Checkout': cvr_cart_checkout,
            'CVR Checkoutâ†’Compra': cvr_checkout_purchase,
        })

    df_disp = pd.DataFrame(rows)
    pct_cols = {c: 2 for c in df_disp.columns if c != header_label}

    _format_dataframe_to_markdown(
        df_disp,
        f"TABLA: TENDENCIA_RATIOS",
        log_func,
        pct_cols_fmt=pct_cols,
        numeric_cols_for_alignment=list(pct_cols.keys()),
    )


def _generar_tabla_bitacora_entidad(entity_level, entity_name, df_daily_entity,
                                   bitacora_periods_list, detected_currency, log_func, period_type="Weeks"):
    """Build a period-over-period table for a single entity within the report."""

    original_locale = locale.getlocale(locale.LC_TIME) 
    try:
        locale_candidates = ['es_ES.UTF-8', 'es_ES', 'Spanish_Spain', 'Spanish']
        locale_set = False
        for loc_candidate in locale_candidates:
            try:
                locale.setlocale(locale.LC_TIME, loc_candidate)
                # log_func(f"Locale para fechas (tabla entidad) configurado a: {loc_candidate}") # Comentado para reducir logs
                locale_set = True
                break
            except locale.Error:
                continue
        if not locale_set:
            log_func("Adv: No se pudo configurar el locale a espaÃ±ol para nombres de meses en tabla entidad. Se usarÃ¡n nombres en inglÃ©s por defecto.")
    except Exception as e_locale_set:
        log_func(f"Adv: Error al intentar configurar locale en tabla entidad: {e_locale_set}")

    
    header_label = entity_level.capitalize()
    log_func(f"\n\n--------------------------------------------------------------------------------")
    title_map = {'Weeks': 'Semanal', 'Months': 'Mensual', 'Biweekly': 'Quincenal'}
    log_func(f" {header_label}: {entity_name} - Comparativa {title_map.get(period_type, period_type)}")
    log_func(f"--------------------------------------------------------------------------------")

    if df_daily_entity is None or df_daily_entity.empty or 'date' not in df_daily_entity.columns:
        log_func("   No hay datos diarios para generar la tabla de bitÃ¡cora.")
        try:
            locale.setlocale(locale.LC_TIME, original_locale)
        except locale.Error as loc_err:
            log_func(f"Adv: error restaurando locale: {loc_err}")
        return
    if not bitacora_periods_list: 
        log_func("   No se proporcionaron perÃ­odos para la bitÃ¡cora.")
        try:
            locale.setlocale(locale.LC_TIME, original_locale)
        except locale.Error as loc_err:
            log_func(f"Adv: error restaurando locale: {loc_err}")
        return

    results_by_period = {} 
    period_labels_for_table = []     

    log_func(f"  Calculando mÃ©tricas para perÃ­odos ({'Semanas' if period_type == 'Weeks' else 'Meses'})...")
    for i, (start_dt, end_dt, original_label_from_list) in enumerate(bitacora_periods_list): 
        current_period_table_label = original_label_from_list 
        period_labels_for_table.append(current_period_table_label)
        
        df_period_subset = df_daily_entity[ 
            (df_daily_entity['date'] >= start_dt) & 
            (df_daily_entity['date'] <= end_dt)
        ].copy()
        period_identifier_tuple = (start_dt.date(), end_dt.date()) 
        results_by_period[original_label_from_list] = _calcular_metricas_agregadas_y_estabilidad(df_period_subset, period_identifier_tuple, log_func) 
        # log_func(f"    -> MÃ©tricas para '{original_label_from_list}' calculadas ({results_by_period[original_label_from_list].get('date_range', 'N/A')}).") # Comentado para reducir logs

    metric_map = {
        'Inversion': {'display':'Inversion', 'formatter': lambda x: f"{detected_currency}{fmt_float(x, 2)}"},
        'Ventas_Totales': {'display':'Ventas', 'formatter': lambda x: f"{detected_currency}{fmt_float(x, 2)}"},
        'ROAS': {'display':'ROAS', 'formatter': lambda x: f"{fmt_float(x, 2)}x"},
        'Compras': {'display':'Compras', 'formatter': fmt_int},
        'CPA': {'display':'CPA', 'formatter': lambda x: f"{detected_currency}{fmt_float(x, 2)}"},
        'Ticket_Promedio': {'display':'Ticket Prom.', 'formatter': lambda x: f"{detected_currency}{fmt_float(x, 2)}"},
        'Impresiones': {'display':'Impresiones', 'formatter': fmt_int},
        'Alcance': {'display':'Alcance', 'formatter': fmt_int},
        'Frecuencia': {'display':'Frecuencia', 'formatter': lambda x: fmt_float(x, 2)},
        'CPM': {'display':'CPM', 'formatter': lambda x: f"{detected_currency}{fmt_float(x, 2)}"},
        'Clics': {'display':'Clics (Link)', 'formatter': fmt_int},
        'CTR': {'display':'CTR (Link) %', 'formatter': lambda x: fmt_pct(x, 2)},
        'Clics Salientes': {'display':'Clics (Out)', 'formatter': fmt_int},
        'CTR Saliente': {'display':'CTR (Out) %', 'formatter': lambda x: fmt_pct(x, 2)},
        'Visitas': {'display':'Visitas LP', 'formatter': fmt_int},
        'LVP_Rate_%': {'display':'Tasa Visita LP %', 'formatter': lambda x: fmt_pct(x, 1)},
        'Conv_Rate_%': {'display':'Tasa Compra %', 'formatter': lambda x: fmt_pct(x, 1)},
        'Tiempo_Promedio': {'display':'Tiempo RV (s)', 'formatter': lambda x: fmt_float(x,1)},
        'RV25_%': {'display': 'RV 25%','formatter': lambda x: fmt_pct(x, 1)},
        'RV75_%': {'display': 'RV 75%','formatter': lambda x: fmt_pct(x, 1)},
        'RV100_%': {'display': 'RV 100%','formatter': lambda x: fmt_pct(x, 1)},
        'Presupuesto_Campana': {'display':'Presup. CampaÃ±a', 'formatter': lambda x: f"{detected_currency}{fmt_float(x,2)}"},
        'Presupuesto_Adset': {'display':'Presup. Adset', 'formatter': lambda x: f"{detected_currency}{fmt_float(x,2)}"},
        'Objetivo': {'display':'Objetivo', 'formatter': lambda x: str(x) if pd.notna(x) else '-'},
        'Tipo_Compra': {'display':'Tipo Compra', 'formatter': lambda x: str(x) if pd.notna(x) else '-'},
        'Estado_Entrega': {'display':'Estado Entrega', 'formatter': lambda x: str(x) if pd.notna(x) else '-'},
        'ROAS_Stability_%': {'display':'Est. ROAS %', 'formatter':fmt_stability},
        'CPA_Stability_%': {'display':'Est. CPA %', 'formatter':fmt_stability},
        'CPM_Stability_%': {'display':'Est. CPM %', 'formatter':fmt_stability},
        'CTR_Stability_%': {'display':'Est. CTR %', 'formatter':fmt_stability},
        'IMPR_Stability_%': {'display':'Est. Impr %', 'formatter':fmt_stability},
        'CTR_DIV_FREQ_RATIO_Stability_%': {'display':'Est. CTR/Freq %', 'formatter':fmt_stability}
    }
    order = [ 
        'Inversion', 'Ventas_Totales', 'ROAS', 'Compras', 'CPA', 'Ticket_Promedio',
        'Impresiones', 'Alcance', 'Frecuencia', 'CPM',
        'Presupuesto_Campana', 'Presupuesto_Adset', 'Objetivo', 'Tipo_Compra', 'Estado_Entrega',
        'Clics', 'CTR', 'Clics Salientes', 'CTR Saliente', 'Visitas', 'LVP_Rate_%', 'Conv_Rate_%',
        'Tiempo_Promedio', 'RV25_%', 'RV75_%', 'RV100_%',
        'ROAS_Stability_%', 'CPA_Stability_%', 'CPM_Stability_%', 'CTR_Stability_%', 'IMPR_Stability_%', 'CTR_DIV_FREQ_RATIO_Stability_%'
    ]
    headers = ["MÃ©trica"] + period_labels_for_table 
    rows = []
    stability_keys_map = {v['display']: k for k,v in metric_map.items() if 'Stability' in k} 

    for internal_key in order: 
        info = metric_map.get(internal_key)
        if not info: continue 
        display_name = info['display'] 
        fmt = info['formatter']        
        row_vals = [display_name]      
        is_stab_metric = 'Stability' in internal_key 

        for i, (_, _, original_period_label) in enumerate(bitacora_periods_list): 
            period_results = results_by_period.get(original_period_label) 
            current_raw = period_results.get(internal_key, np.nan) if period_results else np.nan 

            if is_stab_metric and (period_results is None or not period_results.get('is_complete', False)):
                 formatted_val = '-'
            else:
                 formatted_val = fmt(current_raw) if pd.notna(current_raw) else '-'

            var_vs_prev_fmt = '-' 
            if not is_stab_metric and i < len(bitacora_periods_list) - 1: 
                prev_original_label_for_comparison = bitacora_periods_list[i+1][2] 
                prev_results_for_comparison = results_by_period.get(prev_original_label_for_comparison)
                if prev_results_for_comparison:
                    prev_raw_for_comparison = prev_results_for_comparison.get(internal_key, np.nan)
                    var_vs_prev_fmt = variation(current_raw, prev_raw_for_comparison) 
            
            display_cell = f"{formatted_val}" 
            if not is_stab_metric and var_vs_prev_fmt != '-': 
                 display_cell += f" ({var_vs_prev_fmt})"

            row_vals.append(display_cell) 

        rows.append(row_vals) 

    df_disp = pd.DataFrame(rows, columns=headers) 
    numeric_cols_for_alignment = [h for h in headers if h != "MÃ©trica"] 
    stability_cols_display = list(stability_keys_map.keys()) 
    _format_dataframe_to_markdown(df_disp, "", log_func, currency_cols=detected_currency,
                                  stability_cols=stability_cols_display, 
                                  numeric_cols_for_alignment=numeric_cols_for_alignment)

    log_func("\n  **Nota aclaratoria:**")
    if period_type == 'Weeks':
        current_label = 'Semana actual'
        prev_label = 'XÂª semana anterior'
    elif period_type == 'Biweekly':
        current_label = 'Quincena actual'
        prev_label = 'XÂª quincena anterior'
    else:
        current_label = 'Mes actual'
        prev_label = 'XÂº mes anterior'
    log_func(f"  * **{current_label}:** Corresponde al periodo mÃ¡s reciente analizado (0).")
    log_func(f"  * **{prev_label}:** Es el periodo inmediatamente previo (-X).")
    log_func("  * El anÃ¡lisis comparativo (valores en parÃ©ntesis con ðŸ”º/ðŸ”») se realiza siempre contra el perÃ­odo inmediatamente anterior mostrado en la tabla (columna a la derecha).")
    log_func("\n  **Detalle de CÃ¡lculo de MÃ©tricas Clave (BitÃ¡cora):**")
    log_func("  * **InversiÃ³n:** Suma del `Importe gastado` para el perÃ­odo.")
    log_func("  * **Ventas Totales:** Suma del `Valor de conversiÃ³n de compras` para el perÃ­odo.")
    log_func("  * **ROAS (Retorno de la InversiÃ³n Publicitaria):** `Ventas Totales / InversiÃ³n`. Mide la rentabilidad de la publicidad.")
    log_func("  * **Compras:** Suma de `Compras` para el perÃ­odo.")
    log_func("  * **CPA (Costo por AdquisiciÃ³n/Compra):** `InversiÃ³n / Compras`. Costo promedio para generar una compra.")
    log_func("  * **Ticket Promedio:** `Ventas Totales / Compras`. Valor promedio de cada compra.")
    log_func("  * **Impresiones:** Suma de `Impresiones` para el perÃ­odo.")
    log_func("  * **Alcance:** Suma del `Alcance` para el perÃ­odo (Nota: El alcance agregado puede no ser Ãºnico si se suman datos de diferentes niveles sin dedup. AquÃ­ se suma el alcance diario).")
    log_func("  * **Frecuencia:** `Impresiones / Alcance`. NÃºmero promedio de veces que cada persona vio el anuncio.")
    log_func("  * **CPM (Costo por Mil Impresiones):** `(InversiÃ³n / Impresiones) * 1000`. Costo de mostrar el anuncio mil veces.")
    log_func("  * **Clics (Link):** Suma de `Clics en el enlace` para el perÃ­odo.")
    log_func("  * **CTR (Link) % (Tasa de Clics en el Enlace) %:** `(Clics en el Enlace / Impresiones) * 100`. Porcentaje de impresiones que resultaron en un clic al enlace.")
    log_func("  * **Clics (Out):** Suma de `Clics salientes` para el perÃ­odo.")
    log_func("  * **CTR (Out) % (Tasa de Clics Salientes) %:** `(Clics Salientes / Impresiones) * 100`. Porcentaje de impresiones que resultaron en un clic que lleva fuera de la plataforma.")
    log_func("  * **Visitas LP:** Suma de `Visitas a la pÃ¡gina de destino` para el perÃ­odo.")
    log_func("  * **Tasa Visita LP %:** `(Visitas a la PÃ¡gina de Destino / Clics en el Enlace) * 100`. Porcentaje de clics que resultaron en una carga de la pÃ¡gina de destino.")
    log_func("  * **Tasa Compra % (Tasa de ConversiÃ³n de Compra):** `(Compras / Visitas a la PÃ¡gina de Destino) * 100`. Porcentaje de visitas a la LP que resultaron en una compra.")
    log_func("  * **Tiempo RV (s) (Tiempo Promedio de ReproducciÃ³n de Video):** Promedio del `Tiempo promedio de reproducciÃ³n del video` diario.")
    log_func("  * **% RV X% (Porcentaje de ReproducciÃ³n de Video):** `(Reproducciones hasta X% / Base de Video) * 100`. La base es `Reproducciones de 3 segundos` si es > 0, sino `Impresiones`.")
    log_func("  * **Estabilidad (%):** Mide la consistencia diaria de la mÃ©trica *dentro* del perÃ­odo de la columna. Un % alto indica estabilidad. Se calcula si el perÃ­odo tiene todos sus dÃ­as con datos y cumple umbrales mÃ­nimos. Iconos: âœ… >= 50%, ðŸ† >= 70%.")
    log_func("  ---")
    try:
        locale.setlocale(locale.LC_TIME, original_locale)
    except locale.Error as loc_err:
        log_func(f"Adv: error restaurando locale: {loc_err}")
